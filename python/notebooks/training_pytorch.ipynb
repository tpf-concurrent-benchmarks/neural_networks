{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.3.0%2Bcu118-cp310-cp310-linux_x86_64.whl (839.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m839.6/839.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m847.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Collecting jinja2\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.3.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 pillow-10.2.0 sympy-1.12 torch-2.3.0+cu118 torchaudio-2.3.0+cu118 torchvision-0.18.0+cu118 triton-2.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (1.26.3)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, scipy, pyparsing, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, pandas, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.8.4 pandas-2.2.2 pyparsing-3.1.2 pytz-2024.1 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pytorch-ignite\n",
      "  Downloading pytorch_ignite-0.5.0.post2-py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from pytorch-ignite) (24.0)\n",
      "Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/site-packages (from pytorch-ignite) (2.3.0+cu118)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.8.86)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.8.89)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.4.1.48)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (10.3.0.86)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
      "Installing collected packages: pytorch-ignite\n",
      "Successfully installed pytorch-ignite-0.5.0.post2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.10 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip3.10 install pandas numpy matplotlib scikit-learn\n",
    "!pip3.10 install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import RootMeanSquaredError\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, quantile=0.05):\n",
    "    Q1 = df.quantile(quantile)\n",
    "    Q3 = df.quantile(1-quantile)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    return df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "def apply_feature_engineering(df: pd.DataFrame, keep_outliers) -> pd.DataFrame:\n",
    "    df[\"total_bedrooms\"] = df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].mean())\n",
    "    custom_encoding = {\"ISLAND\": 4, \"NEAR OCEAN\": 3, \"NEAR BAY\": 2, \"<1H OCEAN\": 1, \"INLAND\": 0}\n",
    "    df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n",
    "    df = df.drop(\"ocean_proximity\", axis=1)\n",
    "    df[\"rooms_per_bedroom\"] = df[\"total_rooms\"] / df[\"total_bedrooms\"]\n",
    "    df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]\n",
    "    df[\"encoded_position\"] = df[\"longitude\"] + df[\"latitude\"]\n",
    "    df[\"population_per_bedrooms\"] = df[\"population\"] / df[\"total_bedrooms\"]\n",
    "    df[\"target\"] = df[\"median_house_value\"]\n",
    "    df = df.drop(\"median_house_value\", axis=1)\n",
    "    if not keep_outliers:\n",
    "        df = remove_outliers(df, 0.05)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199/285434561.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n",
      "/tmp/ipykernel_199/285434561.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n"
     ]
    }
   ],
   "source": [
    "df_train = apply_feature_engineering(df_train, True)\n",
    "df_test = apply_feature_engineering(df_test, False)\n",
    "\n",
    "X_train = df_train.drop(\"target\", axis=1)\n",
    "y_train = df_train[\"target\"]\n",
    "\n",
    "X_test = df_test.drop(\"target\", axis=1)\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, inputs: int, layers: list[int], dropout_rate: int = 0, activation_func=\"relu\"):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers_per_dropout = 0 if dropout_rate == 0 else len(layers) // dropout_rate\n",
    "        count = 0\n",
    "        for n_nodes in layers:\n",
    "            self.layers.append(nn.Linear(inputs, n_nodes))\n",
    "            self.layers.append(nn.ReLU()) if activation_func == \"relu\" else nn.Sigmoid()\n",
    "            count += 1\n",
    "            if self.layers_per_dropout == count:\n",
    "                self.layers.append(nn.Dropout(dropout_rate))\n",
    "                count = 0\n",
    "            inputs = n_nodes\n",
    "        self.output_layer = nn.Linear(layers[-1], 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs: int,\n",
    "                layers: list[int],\n",
    "                device: str,\n",
    "                dropout_rate: float = 0.0,\n",
    "                activation_func: str = \"relu\",\n",
    "                optimizer: str = \"adam\"):\n",
    "    model = MLPRegressor(inputs, layers, dropout_rate, activation_func).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, valid_loader, epochs=100, patience=None):\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion)\n",
    "    evaluator = create_supervised_evaluator(model, metrics={'rmse': RootMeanSquaredError()})\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    if patience is not None:\n",
    "        handler = EarlyStopping(patience=patience, score_function=lambda engine: -engine.state.metrics['rmse'], trainer=trainer)\n",
    "        evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_loss(trainer):\n",
    "        print(f\"Epoch {trainer.state.epoch}/{epochs}, Train Loss: {trainer.state.output:.4f}\")\n",
    "        train_losses.append(trainer.state.output)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_metrics(trainer):\n",
    "        evaluator.run(valid_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        print(f\"Epoch {trainer.state.epoch}/{epochs}, Validation RMSE: {metrics['rmse']:.4f}\")\n",
    "        valid_losses.append(metrics['rmse'])\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "X_train_scaled = torch.tensor(pipe.transform(X_train), dtype=torch.float32).to(device)\n",
    "X_test_scaled = torch.tensor(pipe.transform(X_test), dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "\n",
    "model, criterion, optimizer = build_model(X_train_scaled.shape[1], [64, 64, 64, 64, 64, 64], device, 0.1, \"relu\", \"adam\")\n",
    "train_loader = DataLoader(TensorDataset(X_train_scaled, y_train_tensor), batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(TensorDataset(X_test_scaled, y_test_tensor), batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred)**2))\n",
    "\n",
    "def plot_rmse(train_losses, valid_losses):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "    plt.plot(epochs, np.sqrt(train_losses), label=\"Training\")\n",
    "    plt.plot(epochs, valid_losses, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Train Loss: 7543319552.0000\n",
      "Epoch 1/1000, Validation RMSE: 69206.0539\n",
      "Epoch 2/1000, Train Loss: 3296785408.0000\n",
      "Epoch 2/1000, Validation RMSE: 66502.6039\n",
      "Epoch 3/1000, Train Loss: 7081304576.0000\n",
      "Epoch 3/1000, Validation RMSE: 65138.4177\n",
      "Epoch 4/1000, Train Loss: 7533547520.0000\n",
      "Epoch 4/1000, Validation RMSE: 64791.3221\n",
      "Epoch 5/1000, Train Loss: 4451044352.0000\n",
      "Epoch 5/1000, Validation RMSE: 64762.1042\n",
      "Epoch 6/1000, Train Loss: 1245261568.0000\n",
      "Epoch 6/1000, Validation RMSE: 62914.3442\n",
      "Epoch 7/1000, Train Loss: 3471334144.0000\n",
      "Epoch 7/1000, Validation RMSE: 67444.1198\n",
      "Epoch 8/1000, Train Loss: 4604474880.0000\n",
      "Epoch 8/1000, Validation RMSE: 63241.9518\n",
      "Epoch 9/1000, Train Loss: 737921920.0000\n",
      "Epoch 9/1000, Validation RMSE: 61168.0377\n",
      "Epoch 10/1000, Train Loss: 1571496064.0000\n",
      "Epoch 10/1000, Validation RMSE: 61427.3737\n",
      "Epoch 11/1000, Train Loss: 3432131840.0000\n",
      "Epoch 11/1000, Validation RMSE: 60056.4476\n",
      "Epoch 12/1000, Train Loss: 2740997120.0000\n",
      "Epoch 12/1000, Validation RMSE: 60892.0013\n",
      "Epoch 13/1000, Train Loss: 2765539328.0000\n",
      "Epoch 13/1000, Validation RMSE: 59739.9771\n",
      "Epoch 14/1000, Train Loss: 2061875328.0000\n",
      "Epoch 14/1000, Validation RMSE: 59444.6343\n",
      "Epoch 15/1000, Train Loss: 1493544320.0000\n",
      "Epoch 15/1000, Validation RMSE: 58533.2058\n",
      "Epoch 16/1000, Train Loss: 2790202880.0000\n",
      "Epoch 16/1000, Validation RMSE: 58539.9557\n",
      "Epoch 17/1000, Train Loss: 1777361280.0000\n",
      "Epoch 17/1000, Validation RMSE: 58022.5066\n",
      "Epoch 18/1000, Train Loss: 6073316352.0000\n",
      "Epoch 18/1000, Validation RMSE: 57234.6508\n",
      "Epoch 19/1000, Train Loss: 2350520832.0000\n",
      "Epoch 19/1000, Validation RMSE: 57447.3350\n",
      "Epoch 20/1000, Train Loss: 929478080.0000\n",
      "Epoch 20/1000, Validation RMSE: 57071.3163\n",
      "Epoch 21/1000, Train Loss: 2174614016.0000\n",
      "Epoch 21/1000, Validation RMSE: 56574.5842\n",
      "Epoch 22/1000, Train Loss: 2948742144.0000\n",
      "Epoch 22/1000, Validation RMSE: 56358.3849\n",
      "Epoch 23/1000, Train Loss: 3141884672.0000\n",
      "Epoch 23/1000, Validation RMSE: 55839.4175\n",
      "Epoch 24/1000, Train Loss: 2092600960.0000\n",
      "Epoch 24/1000, Validation RMSE: 55948.2019\n",
      "Epoch 25/1000, Train Loss: 1821106944.0000\n",
      "Epoch 25/1000, Validation RMSE: 55510.3375\n",
      "Epoch 26/1000, Train Loss: 2434080512.0000\n",
      "Epoch 26/1000, Validation RMSE: 55961.8596\n",
      "Epoch 27/1000, Train Loss: 2464714752.0000\n",
      "Epoch 27/1000, Validation RMSE: 55585.1801\n",
      "Epoch 28/1000, Train Loss: 1752162048.0000\n",
      "Epoch 28/1000, Validation RMSE: 55789.6632\n",
      "Epoch 29/1000, Train Loss: 4276797952.0000\n",
      "Epoch 29/1000, Validation RMSE: 55440.1491\n",
      "Epoch 30/1000, Train Loss: 1998348928.0000\n",
      "Epoch 30/1000, Validation RMSE: 55153.0597\n",
      "Epoch 31/1000, Train Loss: 333741600.0000\n",
      "Epoch 31/1000, Validation RMSE: 55102.6927\n",
      "Epoch 32/1000, Train Loss: 2751127296.0000\n",
      "Epoch 32/1000, Validation RMSE: 55403.0062\n",
      "Epoch 33/1000, Train Loss: 2749698560.0000\n",
      "Epoch 33/1000, Validation RMSE: 54743.5755\n",
      "Epoch 34/1000, Train Loss: 2684415744.0000\n",
      "Epoch 34/1000, Validation RMSE: 55882.5068\n",
      "Epoch 35/1000, Train Loss: 5240291328.0000\n",
      "Epoch 35/1000, Validation RMSE: 55175.6958\n",
      "Epoch 36/1000, Train Loss: 1050558016.0000\n",
      "Epoch 36/1000, Validation RMSE: 54348.9437\n",
      "Epoch 37/1000, Train Loss: 1819998848.0000\n",
      "Epoch 37/1000, Validation RMSE: 54821.8236\n",
      "Epoch 38/1000, Train Loss: 3125433856.0000\n",
      "Epoch 38/1000, Validation RMSE: 54512.3791\n",
      "Epoch 39/1000, Train Loss: 919520640.0000\n",
      "Epoch 39/1000, Validation RMSE: 54797.9461\n",
      "Epoch 40/1000, Train Loss: 2225068800.0000\n",
      "Epoch 40/1000, Validation RMSE: 53926.0688\n",
      "Epoch 41/1000, Train Loss: 3087558656.0000\n",
      "Epoch 41/1000, Validation RMSE: 54890.5995\n",
      "Epoch 42/1000, Train Loss: 7014683648.0000\n",
      "Epoch 42/1000, Validation RMSE: 54051.0845\n",
      "Epoch 43/1000, Train Loss: 1876367616.0000\n",
      "Epoch 43/1000, Validation RMSE: 54005.4919\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_losses, valid_losses = train_model(model, criterion, optimizer, train_loader, valid_loader, epochs=1000, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_scaled)\n",
    "    rmse_value = rmse(y_test_tensor, y_pred_tensor)\n",
    "    print(\"Root Mean Squared Error:\", rmse_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10.12-kernel",
   "language": "python",
   "name": "python3.10.12-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
