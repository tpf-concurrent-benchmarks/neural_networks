{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, quantile=0.05):\n",
    "    Q1 = df.quantile(quantile)\n",
    "    Q3 = df.quantile(1-quantile)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    return df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "def apply_feature_engineering(df: pd.DataFrame, keep_outliers) -> pd.DataFrame:\n",
    "    df[\"total_bedrooms\"] = df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].mean())\n",
    "    custom_encoding = {\"ISLAND\": 4, \"NEAR OCEAN\": 3, \"NEAR BAY\": 2, \"<1H OCEAN\": 1, \"INLAND\": 0}\n",
    "    df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n",
    "    df = df.drop(\"ocean_proximity\", axis=1)\n",
    "    df[\"rooms_per_bedroom\"] = df[\"total_rooms\"] / df[\"total_bedrooms\"]\n",
    "    df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]\n",
    "    df[\"encoded_position\"] = df[\"longitude\"] + df[\"latitude\"]\n",
    "    df[\"population_per_bedrooms\"] = df[\"population\"] / df[\"total_bedrooms\"]\n",
    "    df[\"target\"] = df[\"median_house_value\"]\n",
    "    df = df.drop(\"median_house_value\", axis=1)\n",
    "    if not keep_outliers:\n",
    "        df = remove_outliers(df, 0.05)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27161/285434561.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n",
      "/tmp/ipykernel_27161/285434561.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n"
     ]
    }
   ],
   "source": [
    "df_train = apply_feature_engineering(df_train, True)\n",
    "df_test = apply_feature_engineering(df_test, False)\n",
    "\n",
    "X_train = df_train.drop(\"target\", axis=1)\n",
    "y_train = df_train[\"target\"]\n",
    "\n",
    "X_test = df_test.drop(\"target\", axis=1)\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69078.54857545583"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([])\n",
    "pipe.steps.append((\"scaler\", StandardScaler()))\n",
    "pipe.steps.append((\"reg\", LinearRegression()))\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_predict = pipe.predict(X_test)\n",
    "metrics.root_mean_squared_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmse(history):\n",
    "    loss = np.sqrt(history[\"loss\"])\n",
    "    val_loss = np.sqrt(history[\"val_loss\"])\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "    plt.plot(loss, label=\"Training\")\n",
    "    plt.plot(val_loss, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.math.square(y_pred - y_true))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs: int,\n",
    "                layers: list[int],\n",
    "                layers_per_dropout: int = 0,\n",
    "                dropout_rate: int = 0,\n",
    "                activation_func = \"relu\",\n",
    "                loss_func = \"mean_squared_error\",\n",
    "                optimizer = \"adam\"):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input((inputs, )))\n",
    "    count = 0\n",
    "    for n_nodes in layers:\n",
    "        model.add(Dense(n_nodes, activation=activation_func))\n",
    "        count += 1\n",
    "        if layers_per_dropout == count:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            count == 0\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss_func, metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "def build_keras_regressor(model,\n",
    "                          epochs = 100,\n",
    "                          batch_size = 100,\n",
    "                          verbose = 0,\n",
    "                          patience = None):\n",
    "    if patience is not None:\n",
    "        early_stop = EarlyStopping(patience = patience, restore_best_weights = True)\n",
    "        callbacks = [early_stop]\n",
    "    else:\n",
    "        callbacks = []\n",
    "    return KerasRegressor(model=model,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=verbose,\n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 3ms/step - loss: 56430411776.0000 - rmse: 237130.6406 - val_loss: 54600482816.0000 - val_rmse: 233333.2500\n",
      "Epoch 2/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56429797376.0000 - rmse: 237183.4062 - val_loss: 54599778304.0000 - val_rmse: 233331.7344\n",
      "Epoch 3/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56428826624.0000 - rmse: 237154.0781 - val_loss: 54598692864.0000 - val_rmse: 233329.3906\n",
      "Epoch 4/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56427409408.0000 - rmse: 237165.3594 - val_loss: 54597140480.0000 - val_rmse: 233326.0781\n",
      "Epoch 5/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56425316352.0000 - rmse: 237161.2812 - val_loss: 54594822144.0000 - val_rmse: 233321.0781\n",
      "Epoch 6/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 56422313984.0000 - rmse: 237173.0000 - val_loss: 54591549440.0000 - val_rmse: 233314.0469\n",
      "Epoch 7/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 56418455552.0000 - rmse: 237079.3906 - val_loss: 54587568128.0000 - val_rmse: 233305.6094\n",
      "Epoch 8/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56413888512.0000 - rmse: 237157.8438 - val_loss: 54583021568.0000 - val_rmse: 233295.8594\n",
      "Epoch 9/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56408743936.0000 - rmse: 237136.1094 - val_loss: 54577917952.0000 - val_rmse: 233284.9219\n",
      "Epoch 10/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56402866176.0000 - rmse: 237155.9375 - val_loss: 54571851776.0000 - val_rmse: 233271.9062\n",
      "Epoch 11/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56395988992.0000 - rmse: 237167.3906 - val_loss: 54564954112.0000 - val_rmse: 233257.1875\n",
      "Epoch 12/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56388177920.0000 - rmse: 237139.0156 - val_loss: 54556917760.0000 - val_rmse: 233240.0000\n",
      "Epoch 13/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56379297792.0000 - rmse: 237137.4688 - val_loss: 54548078592.0000 - val_rmse: 233221.0938\n",
      "Epoch 14/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56369610752.0000 - rmse: 237041.1250 - val_loss: 54538559488.0000 - val_rmse: 233200.7500\n",
      "Epoch 15/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 56359329792.0000 - rmse: 236906.7031 - val_loss: 54528487424.0000 - val_rmse: 233179.1875\n",
      "Epoch 16/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 56348495872.0000 - rmse: 237050.7969 - val_loss: 54517837824.0000 - val_rmse: 233156.3594\n",
      "Epoch 17/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 56337055744.0000 - rmse: 237025.0625 - val_loss: 54506688512.0000 - val_rmse: 233132.5781\n",
      "Epoch 18/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56325070848.0000 - rmse: 236939.0469 - val_loss: 54495043584.0000 - val_rmse: 233107.6094\n",
      "Epoch 19/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 56312557568.0000 - rmse: 236868.9375 - val_loss: 54482923520.0000 - val_rmse: 233081.7344\n",
      "Epoch 20/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56299606016.0000 - rmse: 236859.1406 - val_loss: 54470217728.0000 - val_rmse: 233054.5312\n",
      "Epoch 21/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56286134272.0000 - rmse: 236904.0781 - val_loss: 54457188352.0000 - val_rmse: 233026.6562\n",
      "Epoch 22/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56272187392.0000 - rmse: 236881.5781 - val_loss: 54443646976.0000 - val_rmse: 232997.6406\n",
      "Epoch 23/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56257761280.0000 - rmse: 236881.9375 - val_loss: 54429691904.0000 - val_rmse: 232967.7500\n",
      "Epoch 24/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56242843648.0000 - rmse: 236777.2031 - val_loss: 54415233024.0000 - val_rmse: 232936.8125\n",
      "Epoch 25/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56227459072.0000 - rmse: 236863.7656 - val_loss: 54400360448.0000 - val_rmse: 232904.9688\n",
      "Epoch 26/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56211640320.0000 - rmse: 236778.1719 - val_loss: 54384975872.0000 - val_rmse: 232872.0312\n",
      "Epoch 27/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56195334144.0000 - rmse: 236652.6250 - val_loss: 54369300480.0000 - val_rmse: 232838.4688\n",
      "Epoch 28/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56178622464.0000 - rmse: 236706.4688 - val_loss: 54353104896.0000 - val_rmse: 232803.7812\n",
      "Epoch 29/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56161456128.0000 - rmse: 236646.0625 - val_loss: 54336561152.0000 - val_rmse: 232768.3438\n",
      "Epoch 30/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56143892480.0000 - rmse: 236568.6250 - val_loss: 54319616000.0000 - val_rmse: 232731.9688\n",
      "Epoch 31/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56125906944.0000 - rmse: 236527.7188 - val_loss: 54302208000.0000 - val_rmse: 232694.6562\n",
      "Epoch 32/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56107511808.0000 - rmse: 236485.1719 - val_loss: 54284517376.0000 - val_rmse: 232656.7812\n",
      "Epoch 33/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56088702976.0000 - rmse: 236505.3438 - val_loss: 54266318848.0000 - val_rmse: 232617.7812\n",
      "Epoch 34/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56069435392.0000 - rmse: 236433.3281 - val_loss: 54247727104.0000 - val_rmse: 232577.9062\n",
      "Epoch 35/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56049778688.0000 - rmse: 236350.8594 - val_loss: 54228832256.0000 - val_rmse: 232537.4219\n",
      "Epoch 36/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56029708288.0000 - rmse: 236408.2656 - val_loss: 54209515520.0000 - val_rmse: 232495.9219\n",
      "Epoch 37/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 56009240576.0000 - rmse: 236319.1875 - val_loss: 54189805568.0000 - val_rmse: 232453.6406\n",
      "Epoch 38/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55988404224.0000 - rmse: 236223.3906 - val_loss: 54169747456.0000 - val_rmse: 232410.6094\n",
      "Epoch 39/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55967109120.0000 - rmse: 236198.6406 - val_loss: 54149263360.0000 - val_rmse: 232366.6875\n",
      "Epoch 40/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55945457664.0000 - rmse: 236236.2969 - val_loss: 54128340992.0000 - val_rmse: 232321.7812\n",
      "Epoch 41/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 55923392512.0000 - rmse: 236080.9844 - val_loss: 54107168768.0000 - val_rmse: 232276.3125\n",
      "Epoch 42/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55900917760.0000 - rmse: 236036.3750 - val_loss: 54085464064.0000 - val_rmse: 232229.6562\n",
      "Epoch 43/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55878098944.0000 - rmse: 236035.9375 - val_loss: 54063529984.0000 - val_rmse: 232182.5781\n",
      "Epoch 44/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55854870528.0000 - rmse: 235955.4375 - val_loss: 54041182208.0000 - val_rmse: 232134.5781\n",
      "Epoch 45/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55831257088.0000 - rmse: 235861.3281 - val_loss: 54018441216.0000 - val_rmse: 232085.7344\n",
      "Epoch 46/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55807275008.0000 - rmse: 235870.7969 - val_loss: 53995405312.0000 - val_rmse: 232036.1875\n",
      "Epoch 47/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55782903808.0000 - rmse: 235773.7812 - val_loss: 53971984384.0000 - val_rmse: 231985.8750\n",
      "Epoch 48/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55758135296.0000 - rmse: 235731.6875 - val_loss: 53948243968.0000 - val_rmse: 231934.8594\n",
      "Epoch 49/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55733006336.0000 - rmse: 235709.4531 - val_loss: 53923946496.0000 - val_rmse: 231882.5781\n",
      "Epoch 50/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55707459584.0000 - rmse: 235666.5000 - val_loss: 53899534336.0000 - val_rmse: 231830.0469\n",
      "Epoch 51/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55681613824.0000 - rmse: 235603.7969 - val_loss: 53874556928.0000 - val_rmse: 231776.3438\n",
      "Epoch 52/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55655329792.0000 - rmse: 235584.7969 - val_loss: 53849452544.0000 - val_rmse: 231722.3125\n",
      "Epoch 53/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55628689408.0000 - rmse: 235439.5156 - val_loss: 53823778816.0000 - val_rmse: 231667.0312\n",
      "Epoch 54/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55601643520.0000 - rmse: 235481.1250 - val_loss: 53797756928.0000 - val_rmse: 231610.9688\n",
      "Epoch 55/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55574253568.0000 - rmse: 235373.2656 - val_loss: 53771481088.0000 - val_rmse: 231554.4219\n",
      "Epoch 56/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55546507264.0000 - rmse: 235268.3125 - val_loss: 53744787456.0000 - val_rmse: 231497.0000\n",
      "Epoch 57/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55518380032.0000 - rmse: 235292.0938 - val_loss: 53717942272.0000 - val_rmse: 231439.1406\n",
      "Epoch 58/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 55489884160.0000 - rmse: 235195.6562 - val_loss: 53690490880.0000 - val_rmse: 231379.9219\n",
      "Epoch 59/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55461068800.0000 - rmse: 235149.6719 - val_loss: 53662769152.0000 - val_rmse: 231320.1406\n",
      "Epoch 60/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55431819264.0000 - rmse: 235147.2188 - val_loss: 53634789376.0000 - val_rmse: 231259.8594\n",
      "Epoch 61/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55402192896.0000 - rmse: 234984.9375 - val_loss: 53606256640.0000 - val_rmse: 231198.3438\n",
      "Epoch 62/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55372214272.0000 - rmse: 234912.9688 - val_loss: 53577535488.0000 - val_rmse: 231136.3594\n",
      "Epoch 63/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 55341858816.0000 - rmse: 234929.4219 - val_loss: 53548421120.0000 - val_rmse: 231073.5156\n",
      "Epoch 64/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55311171584.0000 - rmse: 234917.3594 - val_loss: 53518934016.0000 - val_rmse: 231009.9062\n",
      "Epoch 65/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55280103424.0000 - rmse: 234735.8906 - val_loss: 53489102848.0000 - val_rmse: 230945.4375\n",
      "Epoch 66/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 55248683008.0000 - rmse: 234664.8438 - val_loss: 53458894848.0000 - val_rmse: 230880.1875\n",
      "Epoch 67/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55216918528.0000 - rmse: 234622.1250 - val_loss: 53428334592.0000 - val_rmse: 230814.1719\n",
      "Epoch 68/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55184781312.0000 - rmse: 234467.3594 - val_loss: 53397581824.0000 - val_rmse: 230747.7812\n",
      "Epoch 69/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 55152324608.0000 - rmse: 234511.0469 - val_loss: 53366415360.0000 - val_rmse: 230680.3438\n",
      "Epoch 70/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55119474688.0000 - rmse: 234351.7344 - val_loss: 53334966272.0000 - val_rmse: 230612.3594\n",
      "Epoch 71/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55086297088.0000 - rmse: 234287.5469 - val_loss: 53302968320.0000 - val_rmse: 230543.1406\n",
      "Epoch 72/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55052771328.0000 - rmse: 234271.8281 - val_loss: 53270925312.0000 - val_rmse: 230473.8281\n",
      "Epoch 73/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 55018868736.0000 - rmse: 234252.3750 - val_loss: 53238407168.0000 - val_rmse: 230403.4375\n",
      "Epoch 74/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54984540160.0000 - rmse: 234103.8438 - val_loss: 53205635072.0000 - val_rmse: 230332.5312\n",
      "Epoch 75/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54949941248.0000 - rmse: 233996.9062 - val_loss: 53172301824.0000 - val_rmse: 230260.2969\n",
      "Epoch 76/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 54915010560.0000 - rmse: 233952.0781 - val_loss: 53138841600.0000 - val_rmse: 230187.8594\n",
      "Epoch 77/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54879711232.0000 - rmse: 233919.7344 - val_loss: 53104967680.0000 - val_rmse: 230114.4375\n",
      "Epoch 78/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54844076032.0000 - rmse: 233771.2031 - val_loss: 53070811136.0000 - val_rmse: 230040.3906\n",
      "Epoch 79/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54808072192.0000 - rmse: 233793.4688 - val_loss: 53036150784.0000 - val_rmse: 229965.2500\n",
      "Epoch 80/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54771671040.0000 - rmse: 233518.6719 - val_loss: 53001424896.0000 - val_rmse: 229889.9062\n",
      "Epoch 81/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54734942208.0000 - rmse: 233593.6250 - val_loss: 52966055936.0000 - val_rmse: 229813.1250\n",
      "Epoch 82/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54697869312.0000 - rmse: 233557.6250 - val_loss: 52930527232.0000 - val_rmse: 229736.0000\n",
      "Epoch 83/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54660489216.0000 - rmse: 233453.0938 - val_loss: 52894601216.0000 - val_rmse: 229658.0781\n",
      "Epoch 84/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54622760960.0000 - rmse: 233289.2656 - val_loss: 52858556416.0000 - val_rmse: 229579.7812\n",
      "Epoch 85/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54584705024.0000 - rmse: 233311.2344 - val_loss: 52821848064.0000 - val_rmse: 229500.0000\n",
      "Epoch 86/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54546251776.0000 - rmse: 233200.5781 - val_loss: 52785143808.0000 - val_rmse: 229420.2188\n",
      "Epoch 87/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54507536384.0000 - rmse: 232955.5625 - val_loss: 52748005376.0000 - val_rmse: 229339.5156\n",
      "Epoch 88/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54468456448.0000 - rmse: 232867.3906 - val_loss: 52710559744.0000 - val_rmse: 229258.0000\n",
      "Epoch 89/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 54429065216.0000 - rmse: 232934.3906 - val_loss: 52672692224.0000 - val_rmse: 229175.6406\n",
      "Epoch 90/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54389284864.0000 - rmse: 232825.2031 - val_loss: 52634583040.0000 - val_rmse: 229092.7031\n",
      "Epoch 91/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54349234176.0000 - rmse: 232794.3594 - val_loss: 52596191232.0000 - val_rmse: 229009.0469\n",
      "Epoch 92/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54308786176.0000 - rmse: 232649.6406 - val_loss: 52557574144.0000 - val_rmse: 228924.9688\n",
      "Epoch 93/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54268039168.0000 - rmse: 232624.8906 - val_loss: 52518207488.0000 - val_rmse: 228839.1719\n",
      "Epoch 94/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54226882560.0000 - rmse: 232558.8281 - val_loss: 52478984192.0000 - val_rmse: 228753.6406\n",
      "Epoch 95/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54185431040.0000 - rmse: 232402.1094 - val_loss: 52439138304.0000 - val_rmse: 228666.8281\n",
      "Epoch 96/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54143635456.0000 - rmse: 232280.2656 - val_loss: 52399169536.0000 - val_rmse: 228579.5625\n",
      "Epoch 97/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54101520384.0000 - rmse: 232170.5156 - val_loss: 52358651904.0000 - val_rmse: 228491.1719\n",
      "Epoch 98/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54059036672.0000 - rmse: 232072.5781 - val_loss: 52317888512.0000 - val_rmse: 228402.1719\n",
      "Epoch 99/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 54016245760.0000 - rmse: 232065.1719 - val_loss: 52276953088.0000 - val_rmse: 228312.7812\n",
      "Epoch 100/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53973155840.0000 - rmse: 231996.6875 - val_loss: 52235501568.0000 - val_rmse: 228222.2500\n",
      "Epoch 101/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53929701376.0000 - rmse: 231898.0312 - val_loss: 52193968128.0000 - val_rmse: 228131.4219\n",
      "Epoch 102/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 53885902848.0000 - rmse: 231729.0469 - val_loss: 52151898112.0000 - val_rmse: 228039.4219\n",
      "Epoch 103/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 53841747968.0000 - rmse: 231719.6250 - val_loss: 52109590528.0000 - val_rmse: 227946.8750\n",
      "Epoch 104/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53797314560.0000 - rmse: 231657.1719 - val_loss: 52067115008.0000 - val_rmse: 227853.8594\n",
      "Epoch 105/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53752524800.0000 - rmse: 231498.7031 - val_loss: 52024094720.0000 - val_rmse: 227759.6875\n",
      "Epoch 106/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53707358208.0000 - rmse: 231409.2656 - val_loss: 51980951552.0000 - val_rmse: 227665.1719\n",
      "Epoch 107/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53661904896.0000 - rmse: 231335.3281 - val_loss: 51937153024.0000 - val_rmse: 227569.2500\n",
      "Epoch 108/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53616103424.0000 - rmse: 231250.7031 - val_loss: 51893252096.0000 - val_rmse: 227473.0000\n",
      "Epoch 109/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53569966080.0000 - rmse: 231178.3750 - val_loss: 51849019392.0000 - val_rmse: 227376.0000\n",
      "Epoch 110/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53523529728.0000 - rmse: 231071.6562 - val_loss: 51804528640.0000 - val_rmse: 227278.4219\n",
      "Epoch 111/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53476720640.0000 - rmse: 230941.4688 - val_loss: 51759738880.0000 - val_rmse: 227180.0469\n",
      "Epoch 112/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53429596160.0000 - rmse: 230837.5781 - val_loss: 51714560000.0000 - val_rmse: 227080.8594\n",
      "Epoch 113/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53382176768.0000 - rmse: 230674.6719 - val_loss: 51668889600.0000 - val_rmse: 226980.5156\n",
      "Epoch 114/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53334421504.0000 - rmse: 230618.6094 - val_loss: 51623120896.0000 - val_rmse: 226879.9219\n",
      "Epoch 115/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53286379520.0000 - rmse: 230581.7969 - val_loss: 51577188352.0000 - val_rmse: 226778.9219\n",
      "Epoch 116/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 53237985280.0000 - rmse: 230332.5781 - val_loss: 51530956800.0000 - val_rmse: 226677.2188\n",
      "Epoch 117/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53189332992.0000 - rmse: 230297.9375 - val_loss: 51484147712.0000 - val_rmse: 226574.1406\n",
      "Epoch 118/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53140320256.0000 - rmse: 230104.5625 - val_loss: 51437125632.0000 - val_rmse: 226470.6406\n",
      "Epoch 119/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53091045376.0000 - rmse: 229967.9219 - val_loss: 51389997056.0000 - val_rmse: 226366.8125\n",
      "Epoch 120/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 53041459200.0000 - rmse: 229928.0938 - val_loss: 51342450688.0000 - val_rmse: 226262.0469\n",
      "Epoch 121/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52991528960.0000 - rmse: 229925.2344 - val_loss: 51294552064.0000 - val_rmse: 226156.3906\n",
      "Epoch 122/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52941307904.0000 - rmse: 229723.3906 - val_loss: 51246456832.0000 - val_rmse: 226050.3125\n",
      "Epoch 123/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52890816512.0000 - rmse: 229636.2031 - val_loss: 51197984768.0000 - val_rmse: 225943.3594\n",
      "Epoch 124/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52839948288.0000 - rmse: 229389.5938 - val_loss: 51149266944.0000 - val_rmse: 225835.7344\n",
      "Epoch 125/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52788785152.0000 - rmse: 229452.1406 - val_loss: 51100241920.0000 - val_rmse: 225727.4688\n",
      "Epoch 126/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52737351680.0000 - rmse: 229241.2344 - val_loss: 51050782720.0000 - val_rmse: 225618.1406\n",
      "Epoch 127/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52685574144.0000 - rmse: 229121.0156 - val_loss: 51001184256.0000 - val_rmse: 225508.4375\n",
      "Epoch 128/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52633530368.0000 - rmse: 229066.3594 - val_loss: 50951442432.0000 - val_rmse: 225398.4844\n",
      "Epoch 129/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 52581171200.0000 - rmse: 228981.4531 - val_loss: 50900893696.0000 - val_rmse: 225286.5312\n",
      "Epoch 130/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52528455680.0000 - rmse: 228848.4688 - val_loss: 50850701312.0000 - val_rmse: 225175.3906\n",
      "Epoch 131/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52475494400.0000 - rmse: 228738.5156 - val_loss: 50799763456.0000 - val_rmse: 225062.5312\n",
      "Epoch 132/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52422189056.0000 - rmse: 228656.6406 - val_loss: 50748579840.0000 - val_rmse: 224949.0781\n",
      "Epoch 133/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52368556032.0000 - rmse: 228472.5156 - val_loss: 50697342976.0000 - val_rmse: 224835.4219\n",
      "Epoch 134/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52314603520.0000 - rmse: 228389.4062 - val_loss: 50645438464.0000 - val_rmse: 224720.1719\n",
      "Epoch 135/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 52260360192.0000 - rmse: 228215.9844 - val_loss: 50593325056.0000 - val_rmse: 224604.5312\n",
      "Epoch 136/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52205817856.0000 - rmse: 228040.1406 - val_loss: 50541088768.0000 - val_rmse: 224488.5156\n",
      "Epoch 137/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52151025664.0000 - rmse: 227930.3281 - val_loss: 50488582144.0000 - val_rmse: 224371.7812\n",
      "Epoch 138/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52095901696.0000 - rmse: 227957.8906 - val_loss: 50435751936.0000 - val_rmse: 224254.2656\n",
      "Epoch 139/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 52040458240.0000 - rmse: 227759.0312 - val_loss: 50382659584.0000 - val_rmse: 224136.1406\n",
      "Epoch 140/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51984740352.0000 - rmse: 227611.9688 - val_loss: 50329194496.0000 - val_rmse: 224017.1406\n",
      "Epoch 141/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51928719360.0000 - rmse: 227504.0469 - val_loss: 50275393536.0000 - val_rmse: 223897.3125\n",
      "Epoch 142/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51872415744.0000 - rmse: 227366.4688 - val_loss: 50221428736.0000 - val_rmse: 223777.0469\n",
      "Epoch 143/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 51815821312.0000 - rmse: 227245.2188 - val_loss: 50167205888.0000 - val_rmse: 223656.1406\n",
      "Epoch 144/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51758886912.0000 - rmse: 227166.9375 - val_loss: 50112794624.0000 - val_rmse: 223534.7500\n",
      "Epoch 145/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 51701678080.0000 - rmse: 227026.7969 - val_loss: 50057732096.0000 - val_rmse: 223411.8750\n",
      "Epoch 146/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 51644178432.0000 - rmse: 226915.3750 - val_loss: 50002673664.0000 - val_rmse: 223288.9062\n",
      "Epoch 147/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51586379776.0000 - rmse: 226758.9844 - val_loss: 49947176960.0000 - val_rmse: 223164.8281\n",
      "Epoch 148/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51528347648.0000 - rmse: 226644.1719 - val_loss: 49891295232.0000 - val_rmse: 223039.9062\n",
      "Epoch 149/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51469987840.0000 - rmse: 226507.9688 - val_loss: 49835552768.0000 - val_rmse: 222915.2500\n",
      "Epoch 150/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51411341312.0000 - rmse: 226354.6406 - val_loss: 49779212288.0000 - val_rmse: 222789.0781\n",
      "Epoch 151/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51352358912.0000 - rmse: 226231.9844 - val_loss: 49722744832.0000 - val_rmse: 222662.6094\n",
      "Epoch 152/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51293134848.0000 - rmse: 226085.5156 - val_loss: 49666105344.0000 - val_rmse: 222535.6875\n",
      "Epoch 153/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51233611776.0000 - rmse: 225991.8750 - val_loss: 49608818688.0000 - val_rmse: 222407.2500\n",
      "Epoch 154/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51173847040.0000 - rmse: 225820.4531 - val_loss: 49551740928.0000 - val_rmse: 222279.1719\n",
      "Epoch 155/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51113852928.0000 - rmse: 225748.2812 - val_loss: 49493839872.0000 - val_rmse: 222149.1719\n",
      "Epoch 156/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 51053498368.0000 - rmse: 225530.9531 - val_loss: 49435959296.0000 - val_rmse: 222019.1250\n",
      "Epoch 157/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50992857088.0000 - rmse: 225536.6406 - val_loss: 49377988608.0000 - val_rmse: 221888.9062\n",
      "Epoch 158/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 50931900416.0000 - rmse: 225330.0312 - val_loss: 49319669760.0000 - val_rmse: 221757.7500\n",
      "Epoch 159/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 50870652928.0000 - rmse: 225158.6875 - val_loss: 49260699648.0000 - val_rmse: 221625.0469\n",
      "Epoch 160/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50809155584.0000 - rmse: 225001.8125 - val_loss: 49201836032.0000 - val_rmse: 221492.5156\n",
      "Epoch 161/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50747420672.0000 - rmse: 224964.0625 - val_loss: 49142620160.0000 - val_rmse: 221359.0781\n",
      "Epoch 162/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50685399040.0000 - rmse: 224861.2812 - val_loss: 49082990592.0000 - val_rmse: 221224.6562\n",
      "Epoch 163/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 50623098880.0000 - rmse: 224627.0469 - val_loss: 49023258624.0000 - val_rmse: 221089.9062\n",
      "Epoch 164/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 50560512000.0000 - rmse: 224470.5156 - val_loss: 48963039232.0000 - val_rmse: 220954.0000\n",
      "Epoch 165/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50497712128.0000 - rmse: 224383.1094 - val_loss: 48902651904.0000 - val_rmse: 220817.6094\n",
      "Epoch 166/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50434580480.0000 - rmse: 224225.8906 - val_loss: 48842256384.0000 - val_rmse: 220681.0938\n",
      "Epoch 167/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 50371211264.0000 - rmse: 224074.0625 - val_loss: 48781459456.0000 - val_rmse: 220543.5781\n",
      "Epoch 168/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50307551232.0000 - rmse: 223916.6250 - val_loss: 48720347136.0000 - val_rmse: 220405.3438\n",
      "Epoch 169/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 50243616768.0000 - rmse: 223804.7969 - val_loss: 48659247104.0000 - val_rmse: 220267.0000\n",
      "Epoch 170/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 50179383296.0000 - rmse: 223654.0469 - val_loss: 48597409792.0000 - val_rmse: 220126.8750\n",
      "Epoch 171/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 50114904064.0000 - rmse: 223409.8438 - val_loss: 48535650304.0000 - val_rmse: 219986.9219\n",
      "Epoch 172/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 50050195456.0000 - rmse: 223436.7031 - val_loss: 48473403392.0000 - val_rmse: 219845.7031\n",
      "Epoch 173/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 49985212416.0000 - rmse: 223321.7812 - val_loss: 48411078656.0000 - val_rmse: 219704.1875\n",
      "Epoch 174/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 49919979520.0000 - rmse: 223053.0469 - val_loss: 48348344320.0000 - val_rmse: 219561.7031\n",
      "Epoch 175/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49854459904.0000 - rmse: 222921.2656 - val_loss: 48285544448.0000 - val_rmse: 219418.9531\n",
      "Epoch 176/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49788669952.0000 - rmse: 222692.1719 - val_loss: 48222380032.0000 - val_rmse: 219275.2656\n",
      "Epoch 177/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49722621952.0000 - rmse: 222699.8438 - val_loss: 48159363072.0000 - val_rmse: 219131.8750\n",
      "Epoch 178/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49656365056.0000 - rmse: 222475.0156 - val_loss: 48095625216.0000 - val_rmse: 218986.7031\n",
      "Epoch 179/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49589809152.0000 - rmse: 222317.7031 - val_loss: 48031543296.0000 - val_rmse: 218840.6562\n",
      "Epoch 180/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 49522982912.0000 - rmse: 222107.2969 - val_loss: 47967551488.0000 - val_rmse: 218694.7500\n",
      "Epoch 181/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 49455947776.0000 - rmse: 222085.4062 - val_loss: 47903125504.0000 - val_rmse: 218547.6562\n",
      "Epoch 182/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 49388584960.0000 - rmse: 221948.8125 - val_loss: 47838539776.0000 - val_rmse: 218400.2188\n",
      "Epoch 183/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 49320927232.0000 - rmse: 221682.1875 - val_loss: 47773495296.0000 - val_rmse: 218251.5312\n",
      "Epoch 184/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 49253056512.0000 - rmse: 221555.2031 - val_loss: 47708123136.0000 - val_rmse: 218102.0781\n",
      "Epoch 185/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49184923648.0000 - rmse: 221359.7969 - val_loss: 47643017216.0000 - val_rmse: 217953.0781\n",
      "Epoch 186/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 49116622848.0000 - rmse: 221332.7812 - val_loss: 47577227264.0000 - val_rmse: 217802.4219\n",
      "Epoch 187/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 49047977984.0000 - rmse: 221114.7188 - val_loss: 47511220224.0000 - val_rmse: 217651.1875\n",
      "Epoch 188/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48979099648.0000 - rmse: 220943.0625 - val_loss: 47445139456.0000 - val_rmse: 217499.6094\n",
      "Epoch 189/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48910008320.0000 - rmse: 220875.0000 - val_loss: 47378669568.0000 - val_rmse: 217347.0938\n",
      "Epoch 190/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48840568832.0000 - rmse: 220688.5312 - val_loss: 47312453632.0000 - val_rmse: 217195.0000\n",
      "Epoch 191/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48770895872.0000 - rmse: 220591.9062 - val_loss: 47245602816.0000 - val_rmse: 217041.3594\n",
      "Epoch 192/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48701038592.0000 - rmse: 220236.1406 - val_loss: 47177949184.0000 - val_rmse: 216885.8594\n",
      "Epoch 193/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48630890496.0000 - rmse: 220107.8125 - val_loss: 47110754304.0000 - val_rmse: 216731.1406\n",
      "Epoch 194/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48560504832.0000 - rmse: 219995.9844 - val_loss: 47043399680.0000 - val_rmse: 216576.0781\n",
      "Epoch 195/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48489877504.0000 - rmse: 219922.8750 - val_loss: 46975508480.0000 - val_rmse: 216419.5781\n",
      "Epoch 196/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48419045376.0000 - rmse: 219669.8750 - val_loss: 46907207680.0000 - val_rmse: 216262.0938\n",
      "Epoch 197/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 48347963392.0000 - rmse: 219558.9062 - val_loss: 46839226368.0000 - val_rmse: 216105.1875\n",
      "Epoch 198/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48276721664.0000 - rmse: 219397.6094 - val_loss: 46770520064.0000 - val_rmse: 215946.4844\n",
      "Epoch 199/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48205139968.0000 - rmse: 219192.5000 - val_loss: 46701916160.0000 - val_rmse: 215787.9531\n",
      "Epoch 200/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48133361664.0000 - rmse: 219069.2656 - val_loss: 46633095168.0000 - val_rmse: 215628.7344\n",
      "Epoch 201/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 48061349888.0000 - rmse: 218945.0156 - val_loss: 46563774464.0000 - val_rmse: 215468.2656\n",
      "Epoch 202/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47989059584.0000 - rmse: 218787.7812 - val_loss: 46494384128.0000 - val_rmse: 215307.4844\n",
      "Epoch 203/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47916548096.0000 - rmse: 218535.9375 - val_loss: 46424625152.0000 - val_rmse: 215145.7500\n",
      "Epoch 204/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47843827712.0000 - rmse: 218343.3906 - val_loss: 46354784256.0000 - val_rmse: 214983.7031\n",
      "Epoch 205/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47770828800.0000 - rmse: 218207.3125 - val_loss: 46284763136.0000 - val_rmse: 214821.1406\n",
      "Epoch 206/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47697653760.0000 - rmse: 218098.1719 - val_loss: 46214402048.0000 - val_rmse: 214657.6094\n",
      "Epoch 207/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47624237056.0000 - rmse: 217930.9844 - val_loss: 46143725568.0000 - val_rmse: 214493.2969\n",
      "Epoch 208/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47550607360.0000 - rmse: 217793.6406 - val_loss: 46072893440.0000 - val_rmse: 214328.4219\n",
      "Epoch 209/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47476731904.0000 - rmse: 217552.4062 - val_loss: 46001913856.0000 - val_rmse: 214163.0938\n",
      "Epoch 210/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47402627072.0000 - rmse: 217389.0156 - val_loss: 45930676224.0000 - val_rmse: 213997.0469\n",
      "Epoch 211/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47328296960.0000 - rmse: 217174.0625 - val_loss: 45859368960.0000 - val_rmse: 213830.7031\n",
      "Epoch 212/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47253733376.0000 - rmse: 217162.6719 - val_loss: 45788065792.0000 - val_rmse: 213664.2500\n",
      "Epoch 213/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47178989568.0000 - rmse: 216869.9688 - val_loss: 45715718144.0000 - val_rmse: 213495.1875\n",
      "Epoch 214/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 47104045056.0000 - rmse: 216652.4375 - val_loss: 45643657216.0000 - val_rmse: 213326.7500\n",
      "Epoch 215/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 47028838400.0000 - rmse: 216423.0625 - val_loss: 45571559424.0000 - val_rmse: 213158.0312\n",
      "Epoch 216/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46953521152.0000 - rmse: 216315.6875 - val_loss: 45498863616.0000 - val_rmse: 212987.7500\n",
      "Epoch 217/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46877884416.0000 - rmse: 216237.6875 - val_loss: 45426511872.0000 - val_rmse: 212818.1875\n",
      "Epoch 218/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46802104320.0000 - rmse: 216029.8125 - val_loss: 45353545728.0000 - val_rmse: 212647.0312\n",
      "Epoch 219/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46726070272.0000 - rmse: 215845.4531 - val_loss: 45280509952.0000 - val_rmse: 212475.5156\n",
      "Epoch 220/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46649921536.0000 - rmse: 215640.1875 - val_loss: 45206962176.0000 - val_rmse: 212302.7344\n",
      "Epoch 221/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46573522944.0000 - rmse: 215417.2656 - val_loss: 45133737984.0000 - val_rmse: 212130.5312\n",
      "Epoch 222/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46496935936.0000 - rmse: 215249.4375 - val_loss: 45059825664.0000 - val_rmse: 211956.5625\n",
      "Epoch 223/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46420103168.0000 - rmse: 215133.0156 - val_loss: 44986200064.0000 - val_rmse: 211783.1406\n",
      "Epoch 224/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46343077888.0000 - rmse: 214927.5625 - val_loss: 44911947776.0000 - val_rmse: 211608.1250\n",
      "Epoch 225/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46265851904.0000 - rmse: 214856.1875 - val_loss: 44837605376.0000 - val_rmse: 211432.7031\n",
      "Epoch 226/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46188412928.0000 - rmse: 214619.5000 - val_loss: 44763066368.0000 - val_rmse: 211256.7500\n",
      "Epoch 227/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46110756864.0000 - rmse: 214412.8125 - val_loss: 44688646144.0000 - val_rmse: 211080.8281\n",
      "Epoch 228/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 46032961536.0000 - rmse: 214232.3906 - val_loss: 44613685248.0000 - val_rmse: 210903.5156\n",
      "Epoch 229/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45954920448.0000 - rmse: 214044.8438 - val_loss: 44538679296.0000 - val_rmse: 210725.9219\n",
      "Epoch 230/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 45876711424.0000 - rmse: 213833.5938 - val_loss: 44463480832.0000 - val_rmse: 210547.7812\n",
      "Epoch 231/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45798322176.0000 - rmse: 213692.0000 - val_loss: 44387717120.0000 - val_rmse: 210368.0938\n",
      "Epoch 232/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45719719936.0000 - rmse: 213440.4844 - val_loss: 44312125440.0000 - val_rmse: 210188.6875\n",
      "Epoch 233/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45640945664.0000 - rmse: 213301.6562 - val_loss: 44236382208.0000 - val_rmse: 210008.8125\n",
      "Epoch 234/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45561888768.0000 - rmse: 213203.7969 - val_loss: 44160397312.0000 - val_rmse: 209828.1406\n",
      "Epoch 235/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45482627072.0000 - rmse: 212923.7969 - val_loss: 44084121600.0000 - val_rmse: 209646.6406\n",
      "Epoch 236/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45403234304.0000 - rmse: 212710.2656 - val_loss: 44007628800.0000 - val_rmse: 209464.4375\n",
      "Epoch 237/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45323661312.0000 - rmse: 212508.2031 - val_loss: 43931127808.0000 - val_rmse: 209282.0938\n",
      "Epoch 238/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45243858944.0000 - rmse: 212366.8125 - val_loss: 43854442496.0000 - val_rmse: 209099.1406\n",
      "Epoch 239/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45163933696.0000 - rmse: 212143.4688 - val_loss: 43776966656.0000 - val_rmse: 208914.1406\n",
      "Epoch 240/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45083807744.0000 - rmse: 211960.2812 - val_loss: 43700039680.0000 - val_rmse: 208730.2656\n",
      "Epoch 241/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 45003620352.0000 - rmse: 211714.4531 - val_loss: 43622838272.0000 - val_rmse: 208545.5781\n",
      "Epoch 242/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44923129856.0000 - rmse: 211544.4688 - val_loss: 43545915392.0000 - val_rmse: 208361.3438\n",
      "Epoch 243/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44842532864.0000 - rmse: 211317.9375 - val_loss: 43467792384.0000 - val_rmse: 208174.1406\n",
      "Epoch 244/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44761686016.0000 - rmse: 211231.9844 - val_loss: 43390054400.0000 - val_rmse: 207987.6562\n",
      "Epoch 245/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44680695808.0000 - rmse: 211089.4219 - val_loss: 43312001024.0000 - val_rmse: 207800.2656\n",
      "Epoch 246/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44599508992.0000 - rmse: 210850.5781 - val_loss: 43233370112.0000 - val_rmse: 207611.3594\n",
      "Epoch 247/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44518088704.0000 - rmse: 210632.9375 - val_loss: 43155222528.0000 - val_rmse: 207423.3594\n",
      "Epoch 248/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 44436598784.0000 - rmse: 210373.6562 - val_loss: 43076751360.0000 - val_rmse: 207234.4844\n",
      "Epoch 249/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44354940928.0000 - rmse: 210318.5312 - val_loss: 42998132736.0000 - val_rmse: 207044.9688\n",
      "Epoch 250/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44273012736.0000 - rmse: 210109.4844 - val_loss: 42919186432.0000 - val_rmse: 206854.5781\n",
      "Epoch 251/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44190924800.0000 - rmse: 209856.7344 - val_loss: 42839998464.0000 - val_rmse: 206663.4375\n",
      "Epoch 252/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44108656640.0000 - rmse: 209674.2656 - val_loss: 42760724480.0000 - val_rmse: 206471.9062\n",
      "Epoch 253/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 44026281984.0000 - rmse: 209455.9688 - val_loss: 42681360384.0000 - val_rmse: 206279.9062\n",
      "Epoch 254/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43943784448.0000 - rmse: 209303.2969 - val_loss: 42601820160.0000 - val_rmse: 206087.3125\n",
      "Epoch 255/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43861065728.0000 - rmse: 209109.5000 - val_loss: 42522288128.0000 - val_rmse: 205894.6562\n",
      "Epoch 256/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43778273280.0000 - rmse: 208844.5469 - val_loss: 42442043392.0000 - val_rmse: 205700.0000\n",
      "Epoch 257/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43695198208.0000 - rmse: 208772.9531 - val_loss: 42362171392.0000 - val_rmse: 205506.0781\n",
      "Epoch 258/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43612008448.0000 - rmse: 208470.5938 - val_loss: 42282127360.0000 - val_rmse: 205311.5625\n",
      "Epoch 259/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43528654848.0000 - rmse: 208359.0312 - val_loss: 42201825280.0000 - val_rmse: 205116.1875\n",
      "Epoch 260/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43445137408.0000 - rmse: 208108.7188 - val_loss: 42121191424.0000 - val_rmse: 204919.9062\n",
      "Epoch 261/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43361378304.0000 - rmse: 207866.2344 - val_loss: 42040635392.0000 - val_rmse: 204723.5781\n",
      "Epoch 262/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43277512704.0000 - rmse: 207649.5469 - val_loss: 41959415808.0000 - val_rmse: 204525.3906\n",
      "Epoch 263/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 43193540608.0000 - rmse: 207580.0625 - val_loss: 41878110208.0000 - val_rmse: 204326.9062\n",
      "Epoch 264/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43109318656.0000 - rmse: 207252.3750 - val_loss: 41797251072.0000 - val_rmse: 204129.2344\n",
      "Epoch 265/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 43025035264.0000 - rmse: 207141.5781 - val_loss: 41715900416.0000 - val_rmse: 203930.2031\n",
      "Epoch 266/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42940567552.0000 - rmse: 206901.3438 - val_loss: 41634320384.0000 - val_rmse: 203730.3906\n",
      "Epoch 267/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42855907328.0000 - rmse: 206579.6250 - val_loss: 41552437248.0000 - val_rmse: 203529.6406\n",
      "Epoch 268/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42771128320.0000 - rmse: 206440.1406 - val_loss: 41471123456.0000 - val_rmse: 203330.0938\n",
      "Epoch 269/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42686259200.0000 - rmse: 206238.6250 - val_loss: 41389223936.0000 - val_rmse: 203128.9688\n",
      "Epoch 270/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42601205760.0000 - rmse: 206066.4062 - val_loss: 41306812416.0000 - val_rmse: 202926.2969\n",
      "Epoch 271/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42516025344.0000 - rmse: 205848.6250 - val_loss: 41224429568.0000 - val_rmse: 202723.5156\n",
      "Epoch 272/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42430672896.0000 - rmse: 205618.1250 - val_loss: 41142145024.0000 - val_rmse: 202520.7500\n",
      "Epoch 273/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42345197568.0000 - rmse: 205372.0469 - val_loss: 41059848192.0000 - val_rmse: 202317.8125\n",
      "Epoch 274/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42259554304.0000 - rmse: 205232.9219 - val_loss: 40977522688.0000 - val_rmse: 202114.5312\n",
      "Epoch 275/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42173829120.0000 - rmse: 205031.4844 - val_loss: 40894320640.0000 - val_rmse: 201908.9219\n",
      "Epoch 276/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 42087964672.0000 - rmse: 204919.8438 - val_loss: 40811372544.0000 - val_rmse: 201703.7344\n",
      "Epoch 277/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 42001973248.0000 - rmse: 204581.3906 - val_loss: 40728395776.0000 - val_rmse: 201498.2031\n",
      "Epoch 278/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41915879424.0000 - rmse: 204403.1250 - val_loss: 40645140480.0000 - val_rmse: 201291.8281\n",
      "Epoch 279/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41829613568.0000 - rmse: 204233.8906 - val_loss: 40561975296.0000 - val_rmse: 201085.4375\n",
      "Epoch 280/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41743241216.0000 - rmse: 203944.3906 - val_loss: 40478408704.0000 - val_rmse: 200877.8594\n",
      "Epoch 281/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41656750080.0000 - rmse: 203711.8281 - val_loss: 40395010048.0000 - val_rmse: 200670.4688\n",
      "Epoch 282/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41570193408.0000 - rmse: 203561.6406 - val_loss: 40311308288.0000 - val_rmse: 200462.1094\n",
      "Epoch 283/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41483505664.0000 - rmse: 203242.6875 - val_loss: 40227598336.0000 - val_rmse: 200253.5312\n",
      "Epoch 284/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41396711424.0000 - rmse: 203182.5781 - val_loss: 40143585280.0000 - val_rmse: 200043.8906\n",
      "Epoch 285/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41309712384.0000 - rmse: 202917.9375 - val_loss: 40059588608.0000 - val_rmse: 199834.1719\n",
      "Epoch 286/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41222610944.0000 - rmse: 202715.7188 - val_loss: 39975510016.0000 - val_rmse: 199623.9688\n",
      "Epoch 287/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41135329280.0000 - rmse: 202471.3750 - val_loss: 39891423232.0000 - val_rmse: 199413.5312\n",
      "Epoch 288/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 41048023040.0000 - rmse: 202355.2031 - val_loss: 39806656512.0000 - val_rmse: 199201.1719\n",
      "Epoch 289/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40960512000.0000 - rmse: 202003.5625 - val_loss: 39722156032.0000 - val_rmse: 198989.2812\n",
      "Epoch 290/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40872878080.0000 - rmse: 201849.5000 - val_loss: 39637512192.0000 - val_rmse: 198776.7344\n",
      "Epoch 291/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 40785158144.0000 - rmse: 201647.3750 - val_loss: 39552491520.0000 - val_rmse: 198563.0312\n",
      "Epoch 292/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40697307136.0000 - rmse: 201453.2656 - val_loss: 39467597824.0000 - val_rmse: 198349.4844\n",
      "Epoch 293/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40609341440.0000 - rmse: 201172.5938 - val_loss: 39382515712.0000 - val_rmse: 198135.1562\n",
      "Epoch 294/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40521273344.0000 - rmse: 200964.6250 - val_loss: 39297187840.0000 - val_rmse: 197920.0312\n",
      "Epoch 295/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40433135616.0000 - rmse: 200649.2656 - val_loss: 39211995136.0000 - val_rmse: 197704.9688\n",
      "Epoch 296/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40345006080.0000 - rmse: 200533.5156 - val_loss: 39126622208.0000 - val_rmse: 197489.2500\n",
      "Epoch 297/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40256741376.0000 - rmse: 200366.8906 - val_loss: 39041306624.0000 - val_rmse: 197273.4062\n",
      "Epoch 298/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40168398848.0000 - rmse: 200050.4375 - val_loss: 38955917312.0000 - val_rmse: 197057.0938\n",
      "Epoch 299/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 40079912960.0000 - rmse: 199884.3906 - val_loss: 38870298624.0000 - val_rmse: 196840.0469\n",
      "Epoch 300/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39991394304.0000 - rmse: 199636.7969 - val_loss: 38784495616.0000 - val_rmse: 196622.2500\n",
      "Epoch 301/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39902769152.0000 - rmse: 199414.3125 - val_loss: 38698504192.0000 - val_rmse: 196403.7188\n",
      "Epoch 302/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39814008832.0000 - rmse: 199205.9219 - val_loss: 38612901888.0000 - val_rmse: 196185.9219\n",
      "Epoch 303/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39725187072.0000 - rmse: 199029.7344 - val_loss: 38526853120.0000 - val_rmse: 195966.7812\n",
      "Epoch 304/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39636197376.0000 - rmse: 198719.1562 - val_loss: 38440935424.0000 - val_rmse: 195747.7500\n",
      "Epoch 305/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39547207680.0000 - rmse: 198600.5469 - val_loss: 38354337792.0000 - val_rmse: 195526.7031\n",
      "Epoch 306/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 39458070528.0000 - rmse: 198286.8281 - val_loss: 38268014592.0000 - val_rmse: 195306.0469\n",
      "Epoch 307/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39368830976.0000 - rmse: 197970.9375 - val_loss: 38181842944.0000 - val_rmse: 195085.5938\n",
      "Epoch 308/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39279583232.0000 - rmse: 197879.5469 - val_loss: 38095319040.0000 - val_rmse: 194863.9688\n",
      "Epoch 309/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39190138880.0000 - rmse: 197638.9062 - val_loss: 38008680448.0000 - val_rmse: 194641.8594\n",
      "Epoch 310/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39100641280.0000 - rmse: 197473.6719 - val_loss: 37921984512.0000 - val_rmse: 194419.2500\n",
      "Epoch 311/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 39011102720.0000 - rmse: 197162.2969 - val_loss: 37834960896.0000 - val_rmse: 194195.5781\n",
      "Epoch 312/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38921490432.0000 - rmse: 196935.4531 - val_loss: 37748113408.0000 - val_rmse: 193972.0781\n",
      "Epoch 313/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38831779840.0000 - rmse: 196659.5625 - val_loss: 37661736960.0000 - val_rmse: 193749.5938\n",
      "Epoch 314/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38741995520.0000 - rmse: 196488.4219 - val_loss: 37574406144.0000 - val_rmse: 193524.3125\n",
      "Epoch 315/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38652121088.0000 - rmse: 196216.2969 - val_loss: 37487149056.0000 - val_rmse: 193299.0156\n",
      "Epoch 316/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38562115584.0000 - rmse: 196030.0938 - val_loss: 37400547328.0000 - val_rmse: 193075.1406\n",
      "Epoch 317/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38472208384.0000 - rmse: 195868.0312 - val_loss: 37312577536.0000 - val_rmse: 192847.4219\n",
      "Epoch 318/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38382100480.0000 - rmse: 195586.7656 - val_loss: 37225332736.0000 - val_rmse: 192621.3438\n",
      "Epoch 319/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38291951616.0000 - rmse: 195353.5781 - val_loss: 37137903616.0000 - val_rmse: 192394.5312\n",
      "Epoch 320/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38201749504.0000 - rmse: 195115.1875 - val_loss: 37050331136.0000 - val_rmse: 192167.0469\n",
      "Epoch 321/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 38111514624.0000 - rmse: 194799.4688 - val_loss: 36962942976.0000 - val_rmse: 191939.7500\n",
      "Epoch 322/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 38021226496.0000 - rmse: 194690.4844 - val_loss: 36875350016.0000 - val_rmse: 191711.7031\n",
      "Epoch 323/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37930885120.0000 - rmse: 194404.6406 - val_loss: 36787486720.0000 - val_rmse: 191482.6406\n",
      "Epoch 324/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37840490496.0000 - rmse: 194225.9062 - val_loss: 36699545600.0000 - val_rmse: 191253.0781\n",
      "Epoch 325/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37749977088.0000 - rmse: 193960.8750 - val_loss: 36612128768.0000 - val_rmse: 191024.6406\n",
      "Epoch 326/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37659492352.0000 - rmse: 193614.5625 - val_loss: 36524244992.0000 - val_rmse: 190794.7500\n",
      "Epoch 327/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37568905216.0000 - rmse: 193406.1875 - val_loss: 36436221952.0000 - val_rmse: 190564.1094\n",
      "Epoch 328/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37478309888.0000 - rmse: 193226.5156 - val_loss: 36348198912.0000 - val_rmse: 190333.2500\n",
      "Epoch 329/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37387661312.0000 - rmse: 193047.7969 - val_loss: 36260233216.0000 - val_rmse: 190102.2969\n",
      "Epoch 330/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 37296955392.0000 - rmse: 192808.7344 - val_loss: 36172025856.0000 - val_rmse: 189870.3594\n",
      "Epoch 331/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 37206163456.0000 - rmse: 192618.8906 - val_loss: 36084060160.0000 - val_rmse: 189638.7969\n",
      "Epoch 332/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 37115375616.0000 - rmse: 192310.7344 - val_loss: 35995529216.0000 - val_rmse: 189405.4688\n",
      "Epoch 333/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 37024436224.0000 - rmse: 192059.6875 - val_loss: 35907448832.0000 - val_rmse: 189173.0312\n",
      "Epoch 334/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 36933570560.0000 - rmse: 191850.1406 - val_loss: 35819175936.0000 - val_rmse: 188939.7344\n",
      "Epoch 335/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 36842610688.0000 - rmse: 191652.5469 - val_loss: 35730771968.0000 - val_rmse: 188705.8594\n",
      "Epoch 336/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 36751626240.0000 - rmse: 191404.5312 - val_loss: 35642437632.0000 - val_rmse: 188471.9219\n",
      "Epoch 337/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 36660609024.0000 - rmse: 191087.7188 - val_loss: 35553865728.0000 - val_rmse: 188237.0312\n",
      "Epoch 338/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 36569571328.0000 - rmse: 190925.4375 - val_loss: 35465318400.0000 - val_rmse: 188001.8750\n",
      "Epoch 339/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 36478488576.0000 - rmse: 190699.9062 - val_loss: 35376926720.0000 - val_rmse: 187766.8125\n",
      "Epoch 340/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 36387397632.0000 - rmse: 190433.0156 - val_loss: 35288150016.0000 - val_rmse: 187530.4844\n",
      "Epoch 341/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 36296261632.0000 - rmse: 190166.6875 - val_loss: 35199459328.0000 - val_rmse: 187294.0781\n",
      "Epoch 342/1000\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 36205178880.0000 - rmse: 190022.9219 - val_loss: 35110965248.0000 - val_rmse: 187057.8594\n",
      "Epoch 343/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 36114026496.0000 - rmse: 189720.3906 - val_loss: 35022471168.0000 - val_rmse: 186821.4219\n",
      "Epoch 344/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 36022829056.0000 - rmse: 189484.8594 - val_loss: 34933559296.0000 - val_rmse: 186583.4844\n",
      "Epoch 345/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35931631616.0000 - rmse: 189236.0469 - val_loss: 34844786688.0000 - val_rmse: 186345.6406\n",
      "Epoch 346/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35840425984.0000 - rmse: 189002.0000 - val_loss: 34755932160.0000 - val_rmse: 186107.2812\n",
      "Epoch 347/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35749216256.0000 - rmse: 188716.0156 - val_loss: 34667196416.0000 - val_rmse: 185868.9062\n",
      "Epoch 348/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35657912320.0000 - rmse: 188559.0312 - val_loss: 34578403328.0000 - val_rmse: 185630.0625\n",
      "Epoch 349/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 35566600192.0000 - rmse: 188189.0000 - val_loss: 34489647104.0000 - val_rmse: 185391.0312\n",
      "Epoch 350/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 35475267584.0000 - rmse: 188029.3750 - val_loss: 34400759808.0000 - val_rmse: 185151.3125\n",
      "Epoch 351/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35383934976.0000 - rmse: 187780.6250 - val_loss: 34311380992.0000 - val_rmse: 184910.0000\n",
      "Epoch 352/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 35292557312.0000 - rmse: 187498.1719 - val_loss: 34222559232.0000 - val_rmse: 184669.8281\n",
      "Epoch 353/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35201294336.0000 - rmse: 187212.8281 - val_loss: 34133608448.0000 - val_rmse: 184429.0156\n",
      "Epoch 354/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35109957632.0000 - rmse: 187001.3906 - val_loss: 34044940288.0000 - val_rmse: 184188.6562\n",
      "Epoch 355/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35018768384.0000 - rmse: 186811.3750 - val_loss: 33955999744.0000 - val_rmse: 183947.2188\n",
      "Epoch 356/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 34927542272.0000 - rmse: 186555.5469 - val_loss: 33866979328.0000 - val_rmse: 183705.2500\n",
      "Epoch 357/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 34836172800.0000 - rmse: 186341.5781 - val_loss: 33778298880.0000 - val_rmse: 183463.8750\n",
      "Epoch 358/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 34744897536.0000 - rmse: 186093.7656 - val_loss: 33689133056.0000 - val_rmse: 183220.9219\n",
      "Epoch 359/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34653552640.0000 - rmse: 185800.3281 - val_loss: 33600274432.0000 - val_rmse: 182978.3906\n",
      "Epoch 360/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34562236416.0000 - rmse: 185593.0781 - val_loss: 33511098368.0000 - val_rmse: 182734.7188\n",
      "Epoch 361/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34470936576.0000 - rmse: 185296.2031 - val_loss: 33421717504.0000 - val_rmse: 182490.1406\n",
      "Epoch 362/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34379620352.0000 - rmse: 185114.5312 - val_loss: 33333110784.0000 - val_rmse: 182247.3594\n",
      "Epoch 363/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34288328704.0000 - rmse: 184823.0156 - val_loss: 33244030976.0000 - val_rmse: 182002.9688\n",
      "Epoch 364/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 34197071872.0000 - rmse: 184579.6250 - val_loss: 33154715648.0000 - val_rmse: 181757.5781\n",
      "Epoch 365/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34105815040.0000 - rmse: 184313.3281 - val_loss: 33065793536.0000 - val_rmse: 181512.9531\n",
      "Epoch 366/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 34014574592.0000 - rmse: 184067.4531 - val_loss: 32976842752.0000 - val_rmse: 181267.8750\n",
      "Epoch 367/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33923336192.0000 - rmse: 183886.0156 - val_loss: 32887875584.0000 - val_rmse: 181022.4688\n",
      "Epoch 368/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33832179712.0000 - rmse: 183621.7812 - val_loss: 32798685184.0000 - val_rmse: 180776.0938\n",
      "Epoch 369/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33740963840.0000 - rmse: 183325.8750 - val_loss: 32709609472.0000 - val_rmse: 180529.6406\n",
      "Epoch 370/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33649707008.0000 - rmse: 183082.0625 - val_loss: 32621262848.0000 - val_rmse: 180284.9531\n",
      "Epoch 371/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33558636544.0000 - rmse: 182756.9219 - val_loss: 32531857408.0000 - val_rmse: 180037.0156\n",
      "Epoch 372/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33467545600.0000 - rmse: 182608.2812 - val_loss: 32443092992.0000 - val_rmse: 179790.4219\n",
      "Epoch 373/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33376571392.0000 - rmse: 182357.6562 - val_loss: 32353826816.0000 - val_rmse: 179542.1406\n",
      "Epoch 374/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33285441536.0000 - rmse: 182121.0938 - val_loss: 32265170944.0000 - val_rmse: 179295.1875\n",
      "Epoch 375/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33194418176.0000 - rmse: 181795.8750 - val_loss: 32176439296.0000 - val_rmse: 179047.6875\n",
      "Epoch 376/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 33103425536.0000 - rmse: 181599.4219 - val_loss: 32087033856.0000 - val_rmse: 178797.9688\n",
      "Epoch 377/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 33012416512.0000 - rmse: 181328.9688 - val_loss: 31998226432.0000 - val_rmse: 178549.5469\n",
      "Epoch 378/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32921454592.0000 - rmse: 181089.8594 - val_loss: 31909785600.0000 - val_rmse: 178301.8281\n",
      "Epoch 379/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32830552064.0000 - rmse: 180840.3906 - val_loss: 31820865536.0000 - val_rmse: 178052.4219\n",
      "Epoch 380/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32739604480.0000 - rmse: 180680.9375 - val_loss: 31731791872.0000 - val_rmse: 177802.2500\n",
      "Epoch 381/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32648652800.0000 - rmse: 180369.2188 - val_loss: 31642871808.0000 - val_rmse: 177552.0938\n",
      "Epoch 382/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32557780992.0000 - rmse: 180044.4062 - val_loss: 31554013184.0000 - val_rmse: 177301.8281\n",
      "Epoch 383/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32466944000.0000 - rmse: 179903.1875 - val_loss: 31465295872.0000 - val_rmse: 177051.5625\n",
      "Epoch 384/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32376219648.0000 - rmse: 179578.9375 - val_loss: 31376398336.0000 - val_rmse: 176800.3594\n",
      "Epoch 385/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32285472768.0000 - rmse: 179339.8125 - val_loss: 31287941120.0000 - val_rmse: 176550.1875\n",
      "Epoch 386/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32194805760.0000 - rmse: 179166.4375 - val_loss: 31199197184.0000 - val_rmse: 176298.7344\n",
      "Epoch 387/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32104140800.0000 - rmse: 178845.4531 - val_loss: 31110537216.0000 - val_rmse: 176047.2344\n",
      "Epoch 388/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 32013543424.0000 - rmse: 178596.8906 - val_loss: 31021950976.0000 - val_rmse: 175795.5312\n",
      "Epoch 389/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 31923058688.0000 - rmse: 178253.3750 - val_loss: 30933059584.0000 - val_rmse: 175542.5938\n",
      "Epoch 390/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31832561664.0000 - rmse: 178071.4375 - val_loss: 30844827648.0000 - val_rmse: 175291.2188\n",
      "Epoch 391/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31742289920.0000 - rmse: 177858.7969 - val_loss: 30756401152.0000 - val_rmse: 175038.8594\n",
      "Epoch 392/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31652036608.0000 - rmse: 177573.9375 - val_loss: 30667960320.0000 - val_rmse: 174786.1406\n",
      "Epoch 393/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31561836544.0000 - rmse: 177378.6562 - val_loss: 30580013056.0000 - val_rmse: 174534.4219\n",
      "Epoch 394/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 31471716352.0000 - rmse: 177112.5312 - val_loss: 30491412480.0000 - val_rmse: 174280.5156\n",
      "Epoch 395/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31381581824.0000 - rmse: 176900.9219 - val_loss: 30403391488.0000 - val_rmse: 174027.8594\n",
      "Epoch 396/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31291580416.0000 - rmse: 176621.8281 - val_loss: 30315067392.0000 - val_rmse: 173773.9688\n",
      "Epoch 397/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31201630208.0000 - rmse: 176332.8281 - val_loss: 30226944000.0000 - val_rmse: 173520.3125\n",
      "Epoch 398/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31111725056.0000 - rmse: 175977.3594 - val_loss: 30139068416.0000 - val_rmse: 173266.9688\n",
      "Epoch 399/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 31021914112.0000 - rmse: 175743.6094 - val_loss: 30051618816.0000 - val_rmse: 173014.4688\n",
      "Epoch 400/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30932252672.0000 - rmse: 175583.7812 - val_loss: 29963354112.0000 - val_rmse: 172759.2344\n",
      "Epoch 401/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 30842646528.0000 - rmse: 175307.1562 - val_loss: 29875419136.0000 - val_rmse: 172504.6250\n",
      "Epoch 402/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30753087488.0000 - rmse: 175023.3750 - val_loss: 29787944960.0000 - val_rmse: 172250.9688\n",
      "Epoch 403/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30663614464.0000 - rmse: 174768.3438 - val_loss: 29700292608.0000 - val_rmse: 171996.3906\n",
      "Epoch 404/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30574272512.0000 - rmse: 174507.0938 - val_loss: 29612443648.0000 - val_rmse: 171740.8281\n",
      "Epoch 405/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30484940800.0000 - rmse: 174257.4219 - val_loss: 29525104640.0000 - val_rmse: 171486.4531\n",
      "Epoch 406/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30395744256.0000 - rmse: 173944.5469 - val_loss: 29437675520.0000 - val_rmse: 171231.3750\n",
      "Epoch 407/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30306623488.0000 - rmse: 173750.0000 - val_loss: 29350262784.0000 - val_rmse: 170975.9375\n",
      "Epoch 408/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30217549824.0000 - rmse: 173438.9375 - val_loss: 29262725120.0000 - val_rmse: 170719.8125\n",
      "Epoch 409/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30128599040.0000 - rmse: 173205.8906 - val_loss: 29175797760.0000 - val_rmse: 170465.0625\n",
      "Epoch 410/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 30039787520.0000 - rmse: 172976.4844 - val_loss: 29088471040.0000 - val_rmse: 170208.7500\n",
      "Epoch 411/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29950965760.0000 - rmse: 172748.2969 - val_loss: 29001674752.0000 - val_rmse: 169953.6406\n",
      "Epoch 412/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29862303744.0000 - rmse: 172414.7344 - val_loss: 28914380800.0000 - val_rmse: 169696.6250\n",
      "Epoch 413/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 29773662208.0000 - rmse: 172298.2188 - val_loss: 28827742208.0000 - val_rmse: 169441.2188\n",
      "Epoch 414/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29685112832.0000 - rmse: 171947.4688 - val_loss: 28740816896.0000 - val_rmse: 169184.5156\n",
      "Epoch 415/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29596680192.0000 - rmse: 171687.3438 - val_loss: 28653905920.0000 - val_rmse: 168927.5000\n",
      "Epoch 416/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29508315136.0000 - rmse: 171478.5625 - val_loss: 28566837248.0000 - val_rmse: 168669.5781\n",
      "Epoch 417/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29420058624.0000 - rmse: 171080.1875 - val_loss: 28480657408.0000 - val_rmse: 168413.9688\n",
      "Epoch 418/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29331898368.0000 - rmse: 170925.3438 - val_loss: 28394307584.0000 - val_rmse: 168157.4219\n",
      "Epoch 419/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29243852800.0000 - rmse: 170651.1875 - val_loss: 28307812352.0000 - val_rmse: 167900.0000\n",
      "Epoch 420/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29155973120.0000 - rmse: 170415.7969 - val_loss: 28221317120.0000 - val_rmse: 167642.2188\n",
      "Epoch 421/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 29068179456.0000 - rmse: 170132.2031 - val_loss: 28135364608.0000 - val_rmse: 167385.6875\n",
      "Epoch 422/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28980557824.0000 - rmse: 169911.3594 - val_loss: 28049242112.0000 - val_rmse: 167128.2031\n",
      "Epoch 423/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28892964864.0000 - rmse: 169557.5781 - val_loss: 27963336704.0000 - val_rmse: 166871.0312\n",
      "Epoch 424/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28805531648.0000 - rmse: 169470.4844 - val_loss: 27877425152.0000 - val_rmse: 166613.3906\n",
      "Epoch 425/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 28718170112.0000 - rmse: 169153.0156 - val_loss: 27791747072.0000 - val_rmse: 166356.0781\n",
      "Epoch 426/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28630937600.0000 - rmse: 168788.7344 - val_loss: 27705892864.0000 - val_rmse: 166097.8281\n",
      "Epoch 427/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28543791104.0000 - rmse: 168608.8281 - val_loss: 27620530176.0000 - val_rmse: 165840.6406\n",
      "Epoch 428/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28456826880.0000 - rmse: 168387.7656 - val_loss: 27535036416.0000 - val_rmse: 165582.6406\n",
      "Epoch 429/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28370020352.0000 - rmse: 168093.8750 - val_loss: 27449673728.0000 - val_rmse: 165324.6875\n",
      "Epoch 430/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28283318272.0000 - rmse: 167733.4375 - val_loss: 27364542464.0000 - val_rmse: 165066.9688\n",
      "Epoch 431/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28196710400.0000 - rmse: 167594.6406 - val_loss: 27279409152.0000 - val_rmse: 164808.9062\n",
      "Epoch 432/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28110182400.0000 - rmse: 167373.0000 - val_loss: 27194472448.0000 - val_rmse: 164550.9688\n",
      "Epoch 433/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 28023738368.0000 - rmse: 167138.3906 - val_loss: 27109660672.0000 - val_rmse: 164293.0625\n",
      "Epoch 434/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27937435648.0000 - rmse: 166860.0156 - val_loss: 27024629760.0000 - val_rmse: 164034.0000\n",
      "Epoch 435/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27851227136.0000 - rmse: 166519.1875 - val_loss: 26939885568.0000 - val_rmse: 163775.4688\n",
      "Epoch 436/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 27765157888.0000 - rmse: 166321.2188 - val_loss: 26855444480.0000 - val_rmse: 163517.4219\n",
      "Epoch 437/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 27679258624.0000 - rmse: 166032.6406 - val_loss: 26770690048.0000 - val_rmse: 163258.0000\n",
      "Epoch 438/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27593420800.0000 - rmse: 165851.4844 - val_loss: 26686521344.0000 - val_rmse: 163000.0000\n",
      "Epoch 439/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27507884032.0000 - rmse: 165593.2812 - val_loss: 26602020864.0000 - val_rmse: 162740.5312\n",
      "Epoch 440/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27422259200.0000 - rmse: 165235.8125 - val_loss: 26518704128.0000 - val_rmse: 162484.3125\n",
      "Epoch 441/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27336945664.0000 - rmse: 165035.8281 - val_loss: 26434359296.0000 - val_rmse: 162224.4688\n",
      "Epoch 442/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27251734528.0000 - rmse: 164731.3750 - val_loss: 26350520320.0000 - val_rmse: 161965.8125\n",
      "Epoch 443/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27166697472.0000 - rmse: 164433.5625 - val_loss: 26267066368.0000 - val_rmse: 161707.9531\n",
      "Epoch 444/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 27081805824.0000 - rmse: 164165.7188 - val_loss: 26183630848.0000 - val_rmse: 161449.7031\n",
      "Epoch 445/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26997106688.0000 - rmse: 164043.7031 - val_loss: 26100117504.0000 - val_rmse: 161190.8281\n",
      "Epoch 446/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26912548864.0000 - rmse: 163741.9531 - val_loss: 26017300480.0000 - val_rmse: 160933.6562\n",
      "Epoch 447/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26828130304.0000 - rmse: 163438.0781 - val_loss: 25934270464.0000 - val_rmse: 160675.4219\n",
      "Epoch 448/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 26743906304.0000 - rmse: 163242.5781 - val_loss: 25851191296.0000 - val_rmse: 160416.6250\n",
      "Epoch 449/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26659799040.0000 - rmse: 162918.3750 - val_loss: 25768480768.0000 - val_rmse: 160158.5312\n",
      "Epoch 450/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26575874048.0000 - rmse: 162639.8750 - val_loss: 25685944320.0000 - val_rmse: 159900.6094\n",
      "Epoch 451/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 26492119040.0000 - rmse: 162418.4844 - val_loss: 25603299328.0000 - val_rmse: 159641.8906\n",
      "Epoch 452/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26408531968.0000 - rmse: 162201.9531 - val_loss: 25521625088.0000 - val_rmse: 159385.8125\n",
      "Epoch 453/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26325094400.0000 - rmse: 161920.1719 - val_loss: 25439748096.0000 - val_rmse: 159128.6406\n",
      "Epoch 454/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26241800192.0000 - rmse: 161708.6250 - val_loss: 25357355008.0000 - val_rmse: 158869.4688\n",
      "Epoch 455/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26158684160.0000 - rmse: 161462.4219 - val_loss: 25275316224.0000 - val_rmse: 158610.9844\n",
      "Epoch 456/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 26075637760.0000 - rmse: 161130.9062 - val_loss: 25194133504.0000 - val_rmse: 158354.7500\n",
      "Epoch 457/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25992812544.0000 - rmse: 160831.2188 - val_loss: 25112393728.0000 - val_rmse: 158096.4219\n",
      "Epoch 458/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 25910194176.0000 - rmse: 160639.4062 - val_loss: 25031206912.0000 - val_rmse: 157839.3594\n",
      "Epoch 459/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 25827803136.0000 - rmse: 160394.4219 - val_loss: 24950114304.0000 - val_rmse: 157582.1406\n",
      "Epoch 460/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 25745633280.0000 - rmse: 160121.8906 - val_loss: 24869070848.0000 - val_rmse: 157324.7188\n",
      "Epoch 461/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25663555584.0000 - rmse: 159880.0156 - val_loss: 24788453376.0000 - val_rmse: 157068.1875\n",
      "Epoch 462/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25581686784.0000 - rmse: 159486.2344 - val_loss: 24707825664.0000 - val_rmse: 156811.2031\n",
      "Epoch 463/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25499975680.0000 - rmse: 159349.8906 - val_loss: 24627492864.0000 - val_rmse: 156554.7500\n",
      "Epoch 464/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25418471424.0000 - rmse: 159054.5312 - val_loss: 24546848768.0000 - val_rmse: 156296.9062\n",
      "Epoch 465/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25337096192.0000 - rmse: 158711.9062 - val_loss: 24467341312.0000 - val_rmse: 156042.2500\n",
      "Epoch 466/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25255987200.0000 - rmse: 158611.9688 - val_loss: 24387428352.0000 - val_rmse: 155785.8750\n",
      "Epoch 467/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25175023616.0000 - rmse: 158361.2969 - val_loss: 24307535872.0000 - val_rmse: 155529.1250\n",
      "Epoch 468/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25094230016.0000 - rmse: 158007.3906 - val_loss: 24228046848.0000 - val_rmse: 155273.2500\n",
      "Epoch 469/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 25013622784.0000 - rmse: 157767.8750 - val_loss: 24149088256.0000 - val_rmse: 155018.7188\n",
      "Epoch 470/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24933277696.0000 - rmse: 157572.1719 - val_loss: 24069599232.0000 - val_rmse: 154761.9688\n",
      "Epoch 471/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 24852987904.0000 - rmse: 157367.8594 - val_loss: 23990833152.0000 - val_rmse: 154507.1875\n",
      "Epoch 472/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24772954112.0000 - rmse: 157048.4219 - val_loss: 23912218624.0000 - val_rmse: 154252.4531\n",
      "Epoch 473/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24693184512.0000 - rmse: 156693.6406 - val_loss: 23833088000.0000 - val_rmse: 153995.6562\n",
      "Epoch 474/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24613478400.0000 - rmse: 156594.6875 - val_loss: 23755157504.0000 - val_rmse: 153742.2969\n",
      "Epoch 475/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24533983232.0000 - rmse: 156231.4531 - val_loss: 23676809216.0000 - val_rmse: 153487.1406\n",
      "Epoch 476/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24454746112.0000 - rmse: 156063.7656 - val_loss: 23598376960.0000 - val_rmse: 153231.3125\n",
      "Epoch 477/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24375640064.0000 - rmse: 155705.6719 - val_loss: 23520915456.0000 - val_rmse: 152978.2344\n",
      "Epoch 478/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24296822784.0000 - rmse: 155593.1094 - val_loss: 23443275776.0000 - val_rmse: 152724.1406\n",
      "Epoch 479/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24218163200.0000 - rmse: 155243.0000 - val_loss: 23365867520.0000 - val_rmse: 152470.3594\n",
      "Epoch 480/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24139755520.0000 - rmse: 155026.6406 - val_loss: 23288772608.0000 - val_rmse: 152217.2344\n",
      "Epoch 481/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 24061581312.0000 - rmse: 154646.4062 - val_loss: 23211978752.0000 - val_rmse: 151964.6406\n",
      "Epoch 482/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 23983593472.0000 - rmse: 154467.5469 - val_loss: 23135358976.0000 - val_rmse: 151712.2031\n",
      "Epoch 483/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23905906688.0000 - rmse: 154266.3281 - val_loss: 23058540544.0000 - val_rmse: 151458.6875\n",
      "Epoch 484/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23828375552.0000 - rmse: 153978.2344 - val_loss: 22982127616.0000 - val_rmse: 151206.1094\n",
      "Epoch 485/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23751034880.0000 - rmse: 153825.4844 - val_loss: 22906241024.0000 - val_rmse: 150954.8125\n",
      "Epoch 486/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23673985024.0000 - rmse: 153457.5938 - val_loss: 22830211072.0000 - val_rmse: 150702.6562\n",
      "Epoch 487/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23597115392.0000 - rmse: 153264.1562 - val_loss: 22754576384.0000 - val_rmse: 150451.3750\n",
      "Epoch 488/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23520407552.0000 - rmse: 152889.0000 - val_loss: 22679240704.0000 - val_rmse: 150200.6406\n",
      "Epoch 489/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23443972096.0000 - rmse: 152694.4531 - val_loss: 22603960320.0000 - val_rmse: 149949.7188\n",
      "Epoch 490/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23367684096.0000 - rmse: 152501.5781 - val_loss: 22529359872.0000 - val_rmse: 149700.6406\n",
      "Epoch 491/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23291742208.0000 - rmse: 152184.4062 - val_loss: 22454308864.0000 - val_rmse: 149449.5938\n",
      "Epoch 492/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23215951872.0000 - rmse: 151976.5156 - val_loss: 22379913216.0000 - val_rmse: 149200.3750\n",
      "Epoch 493/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 23140380672.0000 - rmse: 151804.6562 - val_loss: 22305671168.0000 - val_rmse: 148951.2188\n",
      "Epoch 494/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 23065079808.0000 - rmse: 151578.9375 - val_loss: 22231130112.0000 - val_rmse: 148700.6406\n",
      "Epoch 495/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22989934592.0000 - rmse: 151205.4375 - val_loss: 22157662208.0000 - val_rmse: 148453.2500\n",
      "Epoch 496/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22915119104.0000 - rmse: 150963.0469 - val_loss: 22083975168.0000 - val_rmse: 148204.7500\n",
      "Epoch 497/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22840465408.0000 - rmse: 150798.8750 - val_loss: 22010785792.0000 - val_rmse: 147957.4688\n",
      "Epoch 498/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22766077952.0000 - rmse: 150546.7344 - val_loss: 21937254400.0000 - val_rmse: 147708.6562\n",
      "Epoch 499/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22691840000.0000 - rmse: 150300.2656 - val_loss: 21864366080.0000 - val_rmse: 147461.5781\n",
      "Epoch 500/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22617845760.0000 - rmse: 150022.5000 - val_loss: 21791928320.0000 - val_rmse: 147215.6250\n",
      "Epoch 501/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 22544121856.0000 - rmse: 149768.9844 - val_loss: 21719138304.0000 - val_rmse: 146968.0781\n",
      "Epoch 502/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22470612992.0000 - rmse: 149523.8438 - val_loss: 21647157248.0000 - val_rmse: 146722.7812\n",
      "Epoch 503/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 22397405184.0000 - rmse: 149340.7812 - val_loss: 21575229440.0000 - val_rmse: 146477.3594\n",
      "Epoch 504/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22324424704.0000 - rmse: 148985.8281 - val_loss: 21503289344.0000 - val_rmse: 146231.4375\n",
      "Epoch 505/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22251673600.0000 - rmse: 148736.5625 - val_loss: 21432025088.0000 - val_rmse: 145987.4219\n",
      "Epoch 506/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 22179237888.0000 - rmse: 148506.0156 - val_loss: 21360513024.0000 - val_rmse: 145742.1406\n",
      "Epoch 507/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 22106996736.0000 - rmse: 148351.4688 - val_loss: 21289664512.0000 - val_rmse: 145498.7656\n",
      "Epoch 508/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 22035005440.0000 - rmse: 148129.7031 - val_loss: 21218887680.0000 - val_rmse: 145255.1875\n",
      "Epoch 509/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21963321344.0000 - rmse: 147815.1250 - val_loss: 21148479488.0000 - val_rmse: 145012.5000\n",
      "Epoch 510/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21891883008.0000 - rmse: 147551.1406 - val_loss: 21078540288.0000 - val_rmse: 144771.0000\n",
      "Epoch 511/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21820708864.0000 - rmse: 147316.2344 - val_loss: 21008758784.0000 - val_rmse: 144529.6562\n",
      "Epoch 512/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 21749807104.0000 - rmse: 147126.1875 - val_loss: 20939151360.0000 - val_rmse: 144288.5000\n",
      "Epoch 513/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21679136768.0000 - rmse: 146863.2969 - val_loss: 20869505024.0000 - val_rmse: 144046.8438\n",
      "Epoch 514/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21608685568.0000 - rmse: 146615.3594 - val_loss: 20800661504.0000 - val_rmse: 143807.5469\n",
      "Epoch 515/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21538521088.0000 - rmse: 146370.7812 - val_loss: 20731615232.0000 - val_rmse: 143567.1406\n",
      "Epoch 516/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21468608512.0000 - rmse: 146159.3750 - val_loss: 20663158784.0000 - val_rmse: 143328.4219\n",
      "Epoch 517/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21398908928.0000 - rmse: 145885.4375 - val_loss: 20594864128.0000 - val_rmse: 143089.8281\n",
      "Epoch 518/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21329547264.0000 - rmse: 145689.1719 - val_loss: 20526264320.0000 - val_rmse: 142849.7812\n",
      "Epoch 519/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21260419072.0000 - rmse: 145419.0312 - val_loss: 20458950656.0000 - val_rmse: 142613.8594\n",
      "Epoch 520/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21191616512.0000 - rmse: 145285.4062 - val_loss: 20391047168.0000 - val_rmse: 142375.4375\n",
      "Epoch 521/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 21122996224.0000 - rmse: 145019.1562 - val_loss: 20323987456.0000 - val_rmse: 142139.6406\n",
      "Epoch 522/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 21054683136.0000 - rmse: 144706.1875 - val_loss: 20257333248.0000 - val_rmse: 141904.8594\n",
      "Epoch 523/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20986687488.0000 - rmse: 144416.8906 - val_loss: 20190388224.0000 - val_rmse: 141668.6562\n",
      "Epoch 524/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20918904832.0000 - rmse: 144267.5312 - val_loss: 20124035072.0000 - val_rmse: 141434.1875\n",
      "Epoch 525/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20851427328.0000 - rmse: 144031.8438 - val_loss: 20057843712.0000 - val_rmse: 141199.8281\n",
      "Epoch 526/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20784164864.0000 - rmse: 143837.0469 - val_loss: 19992129536.0000 - val_rmse: 140966.8438\n",
      "Epoch 527/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20717240320.0000 - rmse: 143587.2188 - val_loss: 19926571008.0000 - val_rmse: 140734.0000\n",
      "Epoch 528/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20650606592.0000 - rmse: 143393.5938 - val_loss: 19861067776.0000 - val_rmse: 140500.9688\n",
      "Epoch 529/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20584216576.0000 - rmse: 143027.9219 - val_loss: 19796199424.0000 - val_rmse: 140269.8125\n",
      "Epoch 530/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 20518105088.0000 - rmse: 142891.3594 - val_loss: 19731554304.0000 - val_rmse: 140039.0938\n",
      "Epoch 531/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20452255744.0000 - rmse: 142630.4844 - val_loss: 19667032064.0000 - val_rmse: 139808.4219\n",
      "Epoch 532/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20386631680.0000 - rmse: 142371.2656 - val_loss: 19603335168.0000 - val_rmse: 139580.2969\n",
      "Epoch 533/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20321388544.0000 - rmse: 142114.4219 - val_loss: 19539265536.0000 - val_rmse: 139350.5000\n",
      "Epoch 534/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20256460800.0000 - rmse: 141977.5625 - val_loss: 19475699712.0000 - val_rmse: 139122.1406\n",
      "Epoch 535/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 20191778816.0000 - rmse: 141735.0000 - val_loss: 19412623360.0000 - val_rmse: 138895.1719\n",
      "Epoch 536/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20127459328.0000 - rmse: 141487.3125 - val_loss: 19349700608.0000 - val_rmse: 138668.3750\n",
      "Epoch 537/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 20063367168.0000 - rmse: 141209.8125 - val_loss: 19287072768.0000 - val_rmse: 138442.2500\n",
      "Epoch 538/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19999672320.0000 - rmse: 140994.0625 - val_loss: 19224768512.0000 - val_rmse: 138216.9688\n",
      "Epoch 539/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 19936233472.0000 - rmse: 140793.5469 - val_loss: 19162916864.0000 - val_rmse: 137992.9688\n",
      "Epoch 540/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19873071104.0000 - rmse: 140515.1406 - val_loss: 19101122560.0000 - val_rmse: 137768.7656\n",
      "Epoch 541/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19810240512.0000 - rmse: 140348.2656 - val_loss: 19039821824.0000 - val_rmse: 137546.0469\n",
      "Epoch 542/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19747651584.0000 - rmse: 140126.3125 - val_loss: 18978951168.0000 - val_rmse: 137324.5156\n",
      "Epoch 543/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19685398528.0000 - rmse: 139899.6562 - val_loss: 18918088704.0000 - val_rmse: 137102.6562\n",
      "Epoch 544/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19623460864.0000 - rmse: 139690.2344 - val_loss: 18857451520.0000 - val_rmse: 136881.2344\n",
      "Epoch 545/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19561779200.0000 - rmse: 139426.7188 - val_loss: 18797846528.0000 - val_rmse: 136663.2656\n",
      "Epoch 546/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19500509184.0000 - rmse: 139243.7812 - val_loss: 18737479680.0000 - val_rmse: 136442.1875\n",
      "Epoch 547/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19439476736.0000 - rmse: 139064.4531 - val_loss: 18678632448.0000 - val_rmse: 136226.2969\n",
      "Epoch 548/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 19378804736.0000 - rmse: 138785.4062 - val_loss: 18619000832.0000 - val_rmse: 136007.1875\n",
      "Epoch 549/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19318380544.0000 - rmse: 138570.1719 - val_loss: 18560243712.0000 - val_rmse: 135790.9219\n",
      "Epoch 550/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19258302464.0000 - rmse: 138432.3750 - val_loss: 18501662720.0000 - val_rmse: 135575.0312\n",
      "Epoch 551/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19198515200.0000 - rmse: 138234.8750 - val_loss: 18443522048.0000 - val_rmse: 135360.3750\n",
      "Epoch 552/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19138953216.0000 - rmse: 137974.4688 - val_loss: 18385600512.0000 - val_rmse: 135146.2188\n",
      "Epoch 553/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19079751680.0000 - rmse: 137737.8281 - val_loss: 18328145920.0000 - val_rmse: 134933.4531\n",
      "Epoch 554/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 19020836864.0000 - rmse: 137548.5625 - val_loss: 18270648320.0000 - val_rmse: 134720.1562\n",
      "Epoch 555/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18962202624.0000 - rmse: 137338.1562 - val_loss: 18213955584.0000 - val_rmse: 134509.5625\n",
      "Epoch 556/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18903902208.0000 - rmse: 137033.1875 - val_loss: 18157430784.0000 - val_rmse: 134299.2031\n",
      "Epoch 557/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 18845915136.0000 - rmse: 136838.0469 - val_loss: 18100641792.0000 - val_rmse: 134087.6406\n",
      "Epoch 558/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18788239360.0000 - rmse: 136677.4688 - val_loss: 18044508160.0000 - val_rmse: 133878.1094\n",
      "Epoch 559/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18730934272.0000 - rmse: 136448.5625 - val_loss: 17988968448.0000 - val_rmse: 133670.5000\n",
      "Epoch 560/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18673909760.0000 - rmse: 136206.9688 - val_loss: 17933742080.0000 - val_rmse: 133463.7812\n",
      "Epoch 561/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18617255936.0000 - rmse: 136034.1562 - val_loss: 17878710272.0000 - val_rmse: 133257.4219\n",
      "Epoch 562/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18560858112.0000 - rmse: 135786.7969 - val_loss: 17824198656.0000 - val_rmse: 133052.7031\n",
      "Epoch 563/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18504816640.0000 - rmse: 135584.1562 - val_loss: 17770004480.0000 - val_rmse: 132848.9375\n",
      "Epoch 564/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18449104896.0000 - rmse: 135432.4219 - val_loss: 17715810304.0000 - val_rmse: 132644.8125\n",
      "Epoch 565/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18393659392.0000 - rmse: 135207.5312 - val_loss: 17662308352.0000 - val_rmse: 132443.0000\n",
      "Epoch 566/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 18338560000.0000 - rmse: 134965.0156 - val_loss: 17608513536.0000 - val_rmse: 132239.7812\n",
      "Epoch 567/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18283728896.0000 - rmse: 134766.9375 - val_loss: 17555576832.0000 - val_rmse: 132039.4688\n",
      "Epoch 568/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18229291008.0000 - rmse: 134635.8750 - val_loss: 17502732288.0000 - val_rmse: 131839.2812\n",
      "Epoch 569/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18175049728.0000 - rmse: 134507.5312 - val_loss: 17450725376.0000 - val_rmse: 131641.8750\n",
      "Epoch 570/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18121261056.0000 - rmse: 134189.1719 - val_loss: 17398382592.0000 - val_rmse: 131442.9688\n",
      "Epoch 571/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18067791872.0000 - rmse: 133955.2500 - val_loss: 17346748416.0000 - val_rmse: 131246.4531\n",
      "Epoch 572/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 18014672896.0000 - rmse: 133768.2656 - val_loss: 17295761408.0000 - val_rmse: 131052.1094\n",
      "Epoch 573/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17961873408.0000 - rmse: 133651.2188 - val_loss: 17244436480.0000 - val_rmse: 130856.1953\n",
      "Epoch 574/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17909383168.0000 - rmse: 133532.5312 - val_loss: 17193840640.0000 - val_rmse: 130662.7891\n",
      "Epoch 575/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 17857198080.0000 - rmse: 133209.1094 - val_loss: 17143511040.0000 - val_rmse: 130470.0859\n",
      "Epoch 576/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17805404160.0000 - rmse: 133001.6094 - val_loss: 17093397504.0000 - val_rmse: 130277.9609\n",
      "Epoch 577/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17753837568.0000 - rmse: 132900.3281 - val_loss: 17043947520.0000 - val_rmse: 130088.1328\n",
      "Epoch 578/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17702660096.0000 - rmse: 132710.7188 - val_loss: 16994664448.0000 - val_rmse: 129898.6094\n",
      "Epoch 579/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17651738624.0000 - rmse: 132420.6250 - val_loss: 16945438720.0000 - val_rmse: 129709.0938\n",
      "Epoch 580/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17601118208.0000 - rmse: 132252.7188 - val_loss: 16896931840.0000 - val_rmse: 129522.0156\n",
      "Epoch 581/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17550862336.0000 - rmse: 132086.8750 - val_loss: 16848394240.0000 - val_rmse: 129334.6328\n",
      "Epoch 582/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17500878848.0000 - rmse: 131822.1719 - val_loss: 16800382976.0000 - val_rmse: 129148.9844\n",
      "Epoch 583/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17451276288.0000 - rmse: 131654.9219 - val_loss: 16752510976.0000 - val_rmse: 128963.5938\n",
      "Epoch 584/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 17402005504.0000 - rmse: 131519.2500 - val_loss: 16705031168.0000 - val_rmse: 128779.4766\n",
      "Epoch 585/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17353048064.0000 - rmse: 131282.6562 - val_loss: 16658280448.0000 - val_rmse: 128597.9531\n",
      "Epoch 586/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17304475648.0000 - rmse: 131017.2812 - val_loss: 16611699712.0000 - val_rmse: 128416.8281\n",
      "Epoch 587/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17256185856.0000 - rmse: 130929.3672 - val_loss: 16565240832.0000 - val_rmse: 128235.9062\n",
      "Epoch 588/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17208274944.0000 - rmse: 130831.4219 - val_loss: 16519049216.0000 - val_rmse: 128055.8281\n",
      "Epoch 589/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17160627200.0000 - rmse: 130561.5859 - val_loss: 16473537536.0000 - val_rmse: 127878.1250\n",
      "Epoch 590/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17113377792.0000 - rmse: 130368.9922 - val_loss: 16428337152.0000 - val_rmse: 127701.3750\n",
      "Epoch 591/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 17066466304.0000 - rmse: 130226.6016 - val_loss: 16383250432.0000 - val_rmse: 127524.8750\n",
      "Epoch 592/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 17019873280.0000 - rmse: 130160.1953 - val_loss: 16338527232.0000 - val_rmse: 127349.5625\n",
      "Epoch 593/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16973575168.0000 - rmse: 129827.4609 - val_loss: 16294324224.0000 - val_rmse: 127176.0391\n",
      "Epoch 594/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16927614976.0000 - rmse: 129605.5312 - val_loss: 16250257408.0000 - val_rmse: 127002.8047\n",
      "Epoch 595/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16881932288.0000 - rmse: 129518.1484 - val_loss: 16206585856.0000 - val_rmse: 126830.9531\n",
      "Epoch 596/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16836577280.0000 - rmse: 129308.4688 - val_loss: 16163367936.0000 - val_rmse: 126660.5703\n",
      "Epoch 597/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16791530496.0000 - rmse: 129127.7266 - val_loss: 16120478720.0000 - val_rmse: 126491.3438\n",
      "Epoch 598/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16746906624.0000 - rmse: 128966.7266 - val_loss: 16077539328.0000 - val_rmse: 126321.6562\n",
      "Epoch 599/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16702487552.0000 - rmse: 128846.1641 - val_loss: 16035206144.0000 - val_rmse: 126154.1484\n",
      "Epoch 600/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16658483200.0000 - rmse: 128583.1406 - val_loss: 15993083904.0000 - val_rmse: 125987.2891\n",
      "Epoch 601/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 16614729728.0000 - rmse: 128436.3125 - val_loss: 15951347712.0000 - val_rmse: 125821.7188\n",
      "Epoch 602/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16571322368.0000 - rmse: 128284.5625 - val_loss: 15910473728.0000 - val_rmse: 125659.3906\n",
      "Epoch 603/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16528331776.0000 - rmse: 128092.0234 - val_loss: 15869108224.0000 - val_rmse: 125494.8906\n",
      "Epoch 604/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16485524480.0000 - rmse: 128017.7266 - val_loss: 15828685824.0000 - val_rmse: 125333.9531\n",
      "Epoch 605/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16443091968.0000 - rmse: 127805.7891 - val_loss: 15788374016.0000 - val_rmse: 125173.2188\n",
      "Epoch 606/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16401010688.0000 - rmse: 127684.1953 - val_loss: 15748357120.0000 - val_rmse: 125013.4844\n",
      "Epoch 607/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16359231488.0000 - rmse: 127485.2656 - val_loss: 15708515328.0000 - val_rmse: 124854.2578\n",
      "Epoch 608/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16317818880.0000 - rmse: 127248.7188 - val_loss: 15668989952.0000 - val_rmse: 124696.0703\n",
      "Epoch 609/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 16276730880.0000 - rmse: 127127.1328 - val_loss: 15630416896.0000 - val_rmse: 124541.5234\n",
      "Epoch 610/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16236043264.0000 - rmse: 126886.5000 - val_loss: 15591430144.0000 - val_rmse: 124385.1484\n",
      "Epoch 611/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16195611648.0000 - rmse: 126837.8594 - val_loss: 15553542144.0000 - val_rmse: 124232.9844\n",
      "Epoch 612/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16155551744.0000 - rmse: 126714.0625 - val_loss: 15515588608.0000 - val_rmse: 124080.3750\n",
      "Epoch 613/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16115781632.0000 - rmse: 126525.3672 - val_loss: 15477953536.0000 - val_rmse: 123928.8672\n",
      "Epoch 614/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16076352512.0000 - rmse: 126303.2109 - val_loss: 15440433152.0000 - val_rmse: 123777.6250\n",
      "Epoch 615/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16037246976.0000 - rmse: 126043.3516 - val_loss: 15403578368.0000 - val_rmse: 123628.9062\n",
      "Epoch 616/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15998387200.0000 - rmse: 126067.7344 - val_loss: 15366770688.0000 - val_rmse: 123480.2188\n",
      "Epoch 617/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15959900160.0000 - rmse: 125908.4375 - val_loss: 15330436096.0000 - val_rmse: 123333.2344\n",
      "Epoch 618/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 15921704960.0000 - rmse: 125721.7969 - val_loss: 15294481408.0000 - val_rmse: 123187.6953\n",
      "Epoch 619/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15883854848.0000 - rmse: 125631.9375 - val_loss: 15258808320.0000 - val_rmse: 123043.0391\n",
      "Epoch 620/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15846286336.0000 - rmse: 125464.2969 - val_loss: 15223262208.0000 - val_rmse: 122898.7812\n",
      "Epoch 621/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15809018880.0000 - rmse: 125322.0312 - val_loss: 15187798016.0000 - val_rmse: 122754.6719\n",
      "Epoch 622/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15772054528.0000 - rmse: 125106.3125 - val_loss: 15153111040.0000 - val_rmse: 122613.5859\n",
      "Epoch 623/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15735398400.0000 - rmse: 125021.4375 - val_loss: 15119021056.0000 - val_rmse: 122474.7188\n",
      "Epoch 624/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15699058688.0000 - rmse: 124792.0078 - val_loss: 15084591104.0000 - val_rmse: 122334.3672\n",
      "Epoch 625/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15663115264.0000 - rmse: 124706.7969 - val_loss: 15050584064.0000 - val_rmse: 122195.5703\n",
      "Epoch 626/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15627422720.0000 - rmse: 124545.6719 - val_loss: 15016800256.0000 - val_rmse: 122057.5625\n",
      "Epoch 627/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 15592065024.0000 - rmse: 124382.1094 - val_loss: 14984016896.0000 - val_rmse: 121923.4375\n",
      "Epoch 628/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15557041152.0000 - rmse: 124338.3359 - val_loss: 14950867968.0000 - val_rmse: 121787.7109\n",
      "Epoch 629/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15522251776.0000 - rmse: 124152.7500 - val_loss: 14918373376.0000 - val_rmse: 121654.5703\n",
      "Epoch 630/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15487844352.0000 - rmse: 124003.6172 - val_loss: 14886106112.0000 - val_rmse: 121522.1484\n",
      "Epoch 631/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15453658112.0000 - rmse: 123889.5234 - val_loss: 14853917696.0000 - val_rmse: 121389.9062\n",
      "Epoch 632/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15419789312.0000 - rmse: 123754.9219 - val_loss: 14822344704.0000 - val_rmse: 121260.0859\n",
      "Epoch 633/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15386159104.0000 - rmse: 123518.3984 - val_loss: 14791261184.0000 - val_rmse: 121132.1328\n",
      "Epoch 634/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 15352775680.0000 - rmse: 123562.4688 - val_loss: 14759965696.0000 - val_rmse: 121003.1953\n",
      "Epoch 635/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 15319732224.0000 - rmse: 123299.3438 - val_loss: 14728646656.0000 - val_rmse: 120874.0234\n",
      "Epoch 636/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15286929408.0000 - rmse: 123228.1484 - val_loss: 14698302464.0000 - val_rmse: 120748.7188\n",
      "Epoch 637/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15254453248.0000 - rmse: 122964.6953 - val_loss: 14667751424.0000 - val_rmse: 120622.4531\n",
      "Epoch 638/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15222206464.0000 - rmse: 122883.6016 - val_loss: 14638020608.0000 - val_rmse: 120499.4531\n",
      "Epoch 639/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15190267904.0000 - rmse: 122851.1016 - val_loss: 14608373760.0000 - val_rmse: 120376.6719\n",
      "Epoch 640/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15158628352.0000 - rmse: 122688.0000 - val_loss: 14578570240.0000 - val_rmse: 120253.1328\n",
      "Epoch 641/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15127240704.0000 - rmse: 122437.7109 - val_loss: 14549422080.0000 - val_rmse: 120132.1797\n",
      "Epoch 642/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15096192000.0000 - rmse: 122402.5156 - val_loss: 14520540160.0000 - val_rmse: 120012.2578\n",
      "Epoch 643/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15065427968.0000 - rmse: 122366.6797 - val_loss: 14491940864.0000 - val_rmse: 119893.3750\n",
      "Epoch 644/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 15034928128.0000 - rmse: 122125.4531 - val_loss: 14463652864.0000 - val_rmse: 119775.6250\n",
      "Epoch 645/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 15004786688.0000 - rmse: 122069.8516 - val_loss: 14435373056.0000 - val_rmse: 119657.8438\n",
      "Epoch 646/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14974877696.0000 - rmse: 121841.7422 - val_loss: 14407393280.0000 - val_rmse: 119541.1953\n",
      "Epoch 647/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14945188864.0000 - rmse: 121780.1016 - val_loss: 14379992064.0000 - val_rmse: 119426.8516\n",
      "Epoch 648/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14915792896.0000 - rmse: 121545.1016 - val_loss: 14352794624.0000 - val_rmse: 119313.2344\n",
      "Epoch 649/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14886666240.0000 - rmse: 121520.4531 - val_loss: 14325684224.0000 - val_rmse: 119199.9062\n",
      "Epoch 650/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14857746432.0000 - rmse: 121417.1719 - val_loss: 14299281408.0000 - val_rmse: 119089.4375\n",
      "Epoch 651/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14829170688.0000 - rmse: 121314.0547 - val_loss: 14272470016.0000 - val_rmse: 118977.1328\n",
      "Epoch 652/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14800784384.0000 - rmse: 121187.6953 - val_loss: 14246242304.0000 - val_rmse: 118867.2109\n",
      "Epoch 653/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 14772620288.0000 - rmse: 121027.9844 - val_loss: 14220363776.0000 - val_rmse: 118758.6094\n",
      "Epoch 654/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14744791040.0000 - rmse: 120992.5234 - val_loss: 14194659328.0000 - val_rmse: 118650.6250\n",
      "Epoch 655/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14717117440.0000 - rmse: 120845.7812 - val_loss: 14168597504.0000 - val_rmse: 118541.0938\n",
      "Epoch 656/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14689778688.0000 - rmse: 120793.9297 - val_loss: 14143815680.0000 - val_rmse: 118436.8516\n",
      "Epoch 657/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14662724608.0000 - rmse: 120518.4688 - val_loss: 14118828032.0000 - val_rmse: 118331.5859\n",
      "Epoch 658/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14635900928.0000 - rmse: 120442.7188 - val_loss: 14093744128.0000 - val_rmse: 118225.8750\n",
      "Epoch 659/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14609338368.0000 - rmse: 120299.9375 - val_loss: 14069287936.0000 - val_rmse: 118122.7344\n",
      "Epoch 660/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 14583065600.0000 - rmse: 120418.8672 - val_loss: 14044944384.0000 - val_rmse: 118019.9531\n",
      "Epoch 661/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14556987392.0000 - rmse: 120163.0781 - val_loss: 14021208064.0000 - val_rmse: 117919.6953\n",
      "Epoch 662/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14531227648.0000 - rmse: 120078.9844 - val_loss: 13997299712.0000 - val_rmse: 117818.5234\n",
      "Epoch 663/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14505713664.0000 - rmse: 119901.7422 - val_loss: 13973936128.0000 - val_rmse: 117719.6562\n",
      "Epoch 664/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14480387072.0000 - rmse: 119886.5156 - val_loss: 13951101952.0000 - val_rmse: 117622.9141\n",
      "Epoch 665/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14455397376.0000 - rmse: 119679.2891 - val_loss: 13927652352.0000 - val_rmse: 117523.5391\n",
      "Epoch 666/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14430490624.0000 - rmse: 119593.4844 - val_loss: 13904898048.0000 - val_rmse: 117426.9766\n",
      "Epoch 667/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 14405934080.0000 - rmse: 119620.9375 - val_loss: 13882504192.0000 - val_rmse: 117331.9062\n",
      "Epoch 668/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14381611008.0000 - rmse: 119453.5625 - val_loss: 13859804160.0000 - val_rmse: 117235.4297\n",
      "Epoch 669/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14357538816.0000 - rmse: 119342.4297 - val_loss: 13837791232.0000 - val_rmse: 117141.8281\n",
      "Epoch 670/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14333600768.0000 - rmse: 119279.3047 - val_loss: 13815862272.0000 - val_rmse: 117048.4844\n",
      "Epoch 671/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14309892096.0000 - rmse: 119206.2500 - val_loss: 13794167808.0000 - val_rmse: 116956.0625\n",
      "Epoch 672/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14286411776.0000 - rmse: 119116.2500 - val_loss: 13772516352.0000 - val_rmse: 116863.8203\n",
      "Epoch 673/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14263147520.0000 - rmse: 118968.9766 - val_loss: 13751085056.0000 - val_rmse: 116772.3281\n",
      "Epoch 674/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14240114688.0000 - rmse: 118830.5859 - val_loss: 13730102272.0000 - val_rmse: 116682.7812\n",
      "Epoch 675/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 14217296896.0000 - rmse: 118824.7266 - val_loss: 13709228032.0000 - val_rmse: 116593.6250\n",
      "Epoch 676/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14194770944.0000 - rmse: 118626.0781 - val_loss: 13688476672.0000 - val_rmse: 116504.8672\n",
      "Epoch 677/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14172365824.0000 - rmse: 118568.8047 - val_loss: 13667924992.0000 - val_rmse: 116416.9531\n",
      "Epoch 678/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14150272000.0000 - rmse: 118495.3906 - val_loss: 13647802368.0000 - val_rmse: 116330.7891\n",
      "Epoch 679/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14128403456.0000 - rmse: 118347.3281 - val_loss: 13627695104.0000 - val_rmse: 116244.6484\n",
      "Epoch 680/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14106657792.0000 - rmse: 118284.8516 - val_loss: 13607921664.0000 - val_rmse: 116159.8438\n",
      "Epoch 681/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14085192704.0000 - rmse: 118248.0547 - val_loss: 13588345856.0000 - val_rmse: 116075.8281\n",
      "Epoch 682/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14063922176.0000 - rmse: 118158.0469 - val_loss: 13568891904.0000 - val_rmse: 115992.3203\n",
      "Epoch 683/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14042819584.0000 - rmse: 118023.9844 - val_loss: 13549389824.0000 - val_rmse: 115908.5000\n",
      "Epoch 684/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 14021913600.0000 - rmse: 117895.0781 - val_loss: 13530384384.0000 - val_rmse: 115826.8281\n",
      "Epoch 685/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 14001182720.0000 - rmse: 117854.2109 - val_loss: 13511533568.0000 - val_rmse: 115745.7109\n",
      "Epoch 686/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13980641280.0000 - rmse: 117865.9688 - val_loss: 13492933632.0000 - val_rmse: 115665.6094\n",
      "Epoch 687/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13960337408.0000 - rmse: 117692.1328 - val_loss: 13473718272.0000 - val_rmse: 115582.8438\n",
      "Epoch 688/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13940092928.0000 - rmse: 117585.9062 - val_loss: 13455365120.0000 - val_rmse: 115503.6953\n",
      "Epoch 689/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13920069632.0000 - rmse: 117533.3516 - val_loss: 13437400064.0000 - val_rmse: 115426.2109\n",
      "Epoch 690/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13900316672.0000 - rmse: 117392.7188 - val_loss: 13419136000.0000 - val_rmse: 115347.3516\n",
      "Epoch 691/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13880712192.0000 - rmse: 117399.4688 - val_loss: 13401149440.0000 - val_rmse: 115269.6328\n",
      "Epoch 692/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13861229568.0000 - rmse: 117195.4531 - val_loss: 13383037952.0000 - val_rmse: 115191.3906\n",
      "Epoch 693/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13841899520.0000 - rmse: 117233.1016 - val_loss: 13365857280.0000 - val_rmse: 115117.0469\n",
      "Epoch 694/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13822789632.0000 - rmse: 117046.7188 - val_loss: 13348258816.0000 - val_rmse: 115040.9297\n",
      "Epoch 695/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13803831296.0000 - rmse: 117103.9609 - val_loss: 13331014656.0000 - val_rmse: 114966.2422\n",
      "Epoch 696/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13785025536.0000 - rmse: 116903.4062 - val_loss: 13313803264.0000 - val_rmse: 114891.6719\n",
      "Epoch 697/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13766322176.0000 - rmse: 116828.0469 - val_loss: 13296476160.0000 - val_rmse: 114816.5234\n",
      "Epoch 698/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13747830784.0000 - rmse: 116753.5703 - val_loss: 13279203328.0000 - val_rmse: 114741.6094\n",
      "Epoch 699/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13729455104.0000 - rmse: 116535.7422 - val_loss: 13262517248.0000 - val_rmse: 114669.1797\n",
      "Epoch 700/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13711233024.0000 - rmse: 116656.1797 - val_loss: 13245912064.0000 - val_rmse: 114597.0391\n",
      "Epoch 701/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13693218816.0000 - rmse: 116526.6328 - val_loss: 13229492224.0000 - val_rmse: 114525.6562\n",
      "Epoch 702/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13675304960.0000 - rmse: 116480.6016 - val_loss: 13212835840.0000 - val_rmse: 114453.2188\n",
      "Epoch 703/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13657555968.0000 - rmse: 116350.3359 - val_loss: 13196560384.0000 - val_rmse: 114382.4141\n",
      "Epoch 704/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13640010752.0000 - rmse: 116243.8984 - val_loss: 13180585984.0000 - val_rmse: 114312.8516\n",
      "Epoch 705/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13622572032.0000 - rmse: 116263.8438 - val_loss: 13164617728.0000 - val_rmse: 114243.2891\n",
      "Epoch 706/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13605304320.0000 - rmse: 116199.1641 - val_loss: 13148490752.0000 - val_rmse: 114172.9766\n",
      "Epoch 707/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13588117504.0000 - rmse: 116078.2031 - val_loss: 13132723200.0000 - val_rmse: 114104.2422\n",
      "Epoch 708/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13571095552.0000 - rmse: 116000.0078 - val_loss: 13117089792.0000 - val_rmse: 114036.0234\n",
      "Epoch 709/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13554180096.0000 - rmse: 115878.7734 - val_loss: 13101523968.0000 - val_rmse: 113968.0703\n",
      "Epoch 710/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13537381376.0000 - rmse: 115812.5547 - val_loss: 13086052352.0000 - val_rmse: 113900.4297\n",
      "Epoch 711/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13520707584.0000 - rmse: 115856.6641 - val_loss: 13070601216.0000 - val_rmse: 113832.9609\n",
      "Epoch 712/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13504186368.0000 - rmse: 115636.1172 - val_loss: 13055311872.0000 - val_rmse: 113766.1094\n",
      "Epoch 713/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13487767552.0000 - rmse: 115669.1562 - val_loss: 13040030720.0000 - val_rmse: 113699.2422\n",
      "Epoch 714/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13471424512.0000 - rmse: 115551.1406 - val_loss: 13025182720.0000 - val_rmse: 113634.2344\n",
      "Epoch 715/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13455236096.0000 - rmse: 115533.3125 - val_loss: 13010034688.0000 - val_rmse: 113567.9062\n",
      "Epoch 716/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13439109120.0000 - rmse: 115468.5312 - val_loss: 12995098624.0000 - val_rmse: 113502.4531\n",
      "Epoch 717/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13423102976.0000 - rmse: 115330.7656 - val_loss: 12980227072.0000 - val_rmse: 113437.2188\n",
      "Epoch 718/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13407223808.0000 - rmse: 115275.6484 - val_loss: 12965633024.0000 - val_rmse: 113373.1719\n",
      "Epoch 719/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13391423488.0000 - rmse: 115144.1797 - val_loss: 12950666240.0000 - val_rmse: 113307.5000\n",
      "Epoch 720/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13375734784.0000 - rmse: 115173.3906 - val_loss: 12936228864.0000 - val_rmse: 113244.0625\n",
      "Epoch 721/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13360078848.0000 - rmse: 115042.8672 - val_loss: 12921874432.0000 - val_rmse: 113180.9766\n",
      "Epoch 722/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13344614400.0000 - rmse: 115046.6172 - val_loss: 12906988544.0000 - val_rmse: 113115.5234\n",
      "Epoch 723/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13329155072.0000 - rmse: 114952.3828 - val_loss: 12892974080.0000 - val_rmse: 113053.8516\n",
      "Epoch 724/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13313869824.0000 - rmse: 114884.1641 - val_loss: 12878368768.0000 - val_rmse: 112989.6094\n",
      "Epoch 725/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13298595840.0000 - rmse: 114804.2969 - val_loss: 12864232448.0000 - val_rmse: 112927.3516\n",
      "Epoch 726/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13283445760.0000 - rmse: 114776.6641 - val_loss: 12849917952.0000 - val_rmse: 112864.2891\n",
      "Epoch 727/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13268381696.0000 - rmse: 114604.9062 - val_loss: 12836103168.0000 - val_rmse: 112803.3906\n",
      "Epoch 728/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13253393408.0000 - rmse: 114608.1562 - val_loss: 12822023168.0000 - val_rmse: 112741.2812\n",
      "Epoch 729/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13238444032.0000 - rmse: 114603.6016 - val_loss: 12807968768.0000 - val_rmse: 112679.2812\n",
      "Epoch 730/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13223604224.0000 - rmse: 114444.5625 - val_loss: 12794055680.0000 - val_rmse: 112617.8281\n",
      "Epoch 731/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13208827904.0000 - rmse: 114434.2656 - val_loss: 12780109824.0000 - val_rmse: 112556.2578\n",
      "Epoch 732/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13194172416.0000 - rmse: 114343.1484 - val_loss: 12766347264.0000 - val_rmse: 112495.4141\n",
      "Epoch 733/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13179572224.0000 - rmse: 114173.4609 - val_loss: 12752657408.0000 - val_rmse: 112434.9062\n",
      "Epoch 734/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13165042688.0000 - rmse: 114227.4844 - val_loss: 12738663424.0000 - val_rmse: 112372.9844\n",
      "Epoch 735/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13150576640.0000 - rmse: 114115.0312 - val_loss: 12725242880.0000 - val_rmse: 112313.5859\n",
      "Epoch 736/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13136150528.0000 - rmse: 114124.6953 - val_loss: 12711467008.0000 - val_rmse: 112252.5703\n",
      "Epoch 737/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13121759232.0000 - rmse: 114054.6562 - val_loss: 12697649152.0000 - val_rmse: 112191.3516\n",
      "Epoch 738/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13107483648.0000 - rmse: 113961.8828 - val_loss: 12684305408.0000 - val_rmse: 112132.2109\n",
      "Epoch 739/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13093250048.0000 - rmse: 113806.1328 - val_loss: 12670868480.0000 - val_rmse: 112072.5703\n",
      "Epoch 740/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13079170048.0000 - rmse: 113741.3359 - val_loss: 12657153024.0000 - val_rmse: 112011.7188\n",
      "Epoch 741/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13065018368.0000 - rmse: 113810.8203 - val_loss: 12643874816.0000 - val_rmse: 111952.7344\n",
      "Epoch 742/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13051004928.0000 - rmse: 113742.5938 - val_loss: 12630332416.0000 - val_rmse: 111892.6328\n",
      "Epoch 743/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13036978176.0000 - rmse: 113529.6562 - val_loss: 12616961024.0000 - val_rmse: 111833.1797\n",
      "Epoch 744/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 13023012864.0000 - rmse: 113583.9453 - val_loss: 12603760640.0000 - val_rmse: 111774.4609\n",
      "Epoch 745/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 13009065984.0000 - rmse: 113631.5859 - val_loss: 12590368768.0000 - val_rmse: 111714.8672\n",
      "Epoch 746/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12995201024.0000 - rmse: 113535.3281 - val_loss: 12576840704.0000 - val_rmse: 111654.6484\n",
      "Epoch 747/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12981370880.0000 - rmse: 113437.0469 - val_loss: 12563383296.0000 - val_rmse: 111594.6719\n",
      "Epoch 748/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12967440384.0000 - rmse: 113398.5078 - val_loss: 12550562816.0000 - val_rmse: 111537.5625\n",
      "Epoch 749/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12953630720.0000 - rmse: 113318.4453 - val_loss: 12537106432.0000 - val_rmse: 111477.5625\n",
      "Epoch 750/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12939976704.0000 - rmse: 113356.4062 - val_loss: 12523706368.0000 - val_rmse: 111417.7578\n",
      "Epoch 751/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12926153728.0000 - rmse: 113150.7969 - val_loss: 12510785536.0000 - val_rmse: 111360.0859\n",
      "Epoch 752/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12912503808.0000 - rmse: 113091.6172 - val_loss: 12497681408.0000 - val_rmse: 111301.5625\n",
      "Epoch 753/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12898840576.0000 - rmse: 113013.6562 - val_loss: 12484481024.0000 - val_rmse: 111242.5625\n",
      "Epoch 754/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12885166080.0000 - rmse: 113121.0078 - val_loss: 12471236608.0000 - val_rmse: 111183.3750\n",
      "Epoch 755/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12871605248.0000 - rmse: 112842.9609 - val_loss: 12458266624.0000 - val_rmse: 111125.3750\n",
      "Epoch 756/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12857973760.0000 - rmse: 112809.5000 - val_loss: 12445189120.0000 - val_rmse: 111066.8516\n",
      "Epoch 757/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12844428288.0000 - rmse: 112917.8047 - val_loss: 12431817728.0000 - val_rmse: 111006.9844\n",
      "Epoch 758/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12830904320.0000 - rmse: 112801.7188 - val_loss: 12419075072.0000 - val_rmse: 110949.8906\n",
      "Epoch 759/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12817454080.0000 - rmse: 112610.1719 - val_loss: 12406082560.0000 - val_rmse: 110891.6328\n",
      "Epoch 760/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12803969024.0000 - rmse: 112667.4688 - val_loss: 12392931328.0000 - val_rmse: 110832.6797\n",
      "Epoch 761/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12790560768.0000 - rmse: 112583.1641 - val_loss: 12379833344.0000 - val_rmse: 110773.8906\n",
      "Epoch 762/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12777121792.0000 - rmse: 112613.1016 - val_loss: 12366796800.0000 - val_rmse: 110715.3672\n",
      "Epoch 763/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12763799552.0000 - rmse: 112450.9453 - val_loss: 12353622016.0000 - val_rmse: 110656.1797\n",
      "Epoch 764/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12750440448.0000 - rmse: 112423.8359 - val_loss: 12340818944.0000 - val_rmse: 110598.6797\n",
      "Epoch 765/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12737154048.0000 - rmse: 112359.2656 - val_loss: 12328385536.0000 - val_rmse: 110542.7656\n",
      "Epoch 766/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12723834880.0000 - rmse: 112300.7500 - val_loss: 12314890240.0000 - val_rmse: 110482.0625\n",
      "Epoch 767/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12710516736.0000 - rmse: 112258.4453 - val_loss: 12302271488.0000 - val_rmse: 110425.2422\n",
      "Epoch 768/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12697277440.0000 - rmse: 112150.9531 - val_loss: 12289002496.0000 - val_rmse: 110365.5156\n",
      "Epoch 769/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12684111872.0000 - rmse: 112056.1484 - val_loss: 12276491264.0000 - val_rmse: 110309.1484\n",
      "Epoch 770/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12670897152.0000 - rmse: 112023.6641 - val_loss: 12263654400.0000 - val_rmse: 110251.2656\n",
      "Epoch 771/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12657755136.0000 - rmse: 112148.0078 - val_loss: 12250399744.0000 - val_rmse: 110191.4609\n",
      "Epoch 772/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12644605952.0000 - rmse: 112001.8906 - val_loss: 12237501440.0000 - val_rmse: 110133.2656\n",
      "Epoch 773/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12631473152.0000 - rmse: 111984.4688 - val_loss: 12225039360.0000 - val_rmse: 110076.9844\n",
      "Epoch 774/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12618386432.0000 - rmse: 111729.1641 - val_loss: 12212151296.0000 - val_rmse: 110018.7656\n",
      "Epoch 775/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12605289472.0000 - rmse: 111749.9688 - val_loss: 12199159808.0000 - val_rmse: 109960.0469\n",
      "Epoch 776/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12592219136.0000 - rmse: 111673.5391 - val_loss: 12186473472.0000 - val_rmse: 109902.6719\n",
      "Epoch 777/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12579229696.0000 - rmse: 111667.4219 - val_loss: 12173629440.0000 - val_rmse: 109844.5391\n",
      "Epoch 778/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12566171648.0000 - rmse: 111627.3984 - val_loss: 12160960512.0000 - val_rmse: 109787.2344\n",
      "Epoch 779/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12553138176.0000 - rmse: 111529.3125 - val_loss: 12148125696.0000 - val_rmse: 109729.0469\n",
      "Epoch 780/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12540101632.0000 - rmse: 111456.2734 - val_loss: 12135334912.0000 - val_rmse: 109671.1094\n",
      "Epoch 781/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12527081472.0000 - rmse: 111512.6094 - val_loss: 12122519552.0000 - val_rmse: 109612.9844\n",
      "Epoch 782/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12514038784.0000 - rmse: 111391.2031 - val_loss: 12109664256.0000 - val_rmse: 109554.6953\n",
      "Epoch 783/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12500987904.0000 - rmse: 111423.4062 - val_loss: 12096925696.0000 - val_rmse: 109496.8672\n",
      "Epoch 784/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12487981056.0000 - rmse: 111220.7109 - val_loss: 12083982336.0000 - val_rmse: 109438.0625\n",
      "Epoch 785/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12474958848.0000 - rmse: 111220.2031 - val_loss: 12071000064.0000 - val_rmse: 109379.0703\n",
      "Epoch 786/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12461950976.0000 - rmse: 111194.3828 - val_loss: 12058377216.0000 - val_rmse: 109321.7109\n",
      "Epoch 787/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12448992256.0000 - rmse: 111059.8828 - val_loss: 12045590528.0000 - val_rmse: 109263.5234\n",
      "Epoch 788/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12436108288.0000 - rmse: 111152.5859 - val_loss: 12032845824.0000 - val_rmse: 109205.5156\n",
      "Epoch 789/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12423116800.0000 - rmse: 110923.8906 - val_loss: 12019735552.0000 - val_rmse: 109145.8281\n",
      "Epoch 790/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12410187776.0000 - rmse: 110847.1875 - val_loss: 12007171072.0000 - val_rmse: 109088.5625\n",
      "Epoch 791/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12397280256.0000 - rmse: 110851.8828 - val_loss: 11994442752.0000 - val_rmse: 109030.5391\n",
      "Epoch 792/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12384363520.0000 - rmse: 110792.1172 - val_loss: 11981529088.0000 - val_rmse: 108971.6484\n",
      "Epoch 793/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12371450880.0000 - rmse: 110788.7266 - val_loss: 11968856064.0000 - val_rmse: 108913.8203\n",
      "Epoch 794/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12358579200.0000 - rmse: 110697.7031 - val_loss: 11956214784.0000 - val_rmse: 108856.0469\n",
      "Epoch 795/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12345757696.0000 - rmse: 110656.2500 - val_loss: 11943735296.0000 - val_rmse: 108799.0938\n",
      "Epoch 796/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12332893184.0000 - rmse: 110521.7031 - val_loss: 11930674176.0000 - val_rmse: 108739.4062\n",
      "Epoch 797/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12320076800.0000 - rmse: 110511.8125 - val_loss: 11918051328.0000 - val_rmse: 108681.6484\n",
      "Epoch 798/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12307181568.0000 - rmse: 110394.2578 - val_loss: 11905308672.0000 - val_rmse: 108623.3281\n",
      "Epoch 799/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12294393856.0000 - rmse: 110393.7422 - val_loss: 11892544512.0000 - val_rmse: 108564.9062\n",
      "Epoch 800/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12281533440.0000 - rmse: 110397.7734 - val_loss: 11879635968.0000 - val_rmse: 108505.7812\n",
      "Epoch 801/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12268767232.0000 - rmse: 110275.0234 - val_loss: 11866909696.0000 - val_rmse: 108447.4609\n",
      "Epoch 802/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12255912960.0000 - rmse: 110128.3516 - val_loss: 11854367744.0000 - val_rmse: 108389.9609\n",
      "Epoch 803/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12243111936.0000 - rmse: 110082.2969 - val_loss: 11841828864.0000 - val_rmse: 108332.4375\n",
      "Epoch 804/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12230360064.0000 - rmse: 110028.9531 - val_loss: 11829037056.0000 - val_rmse: 108273.7422\n",
      "Epoch 805/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12217521152.0000 - rmse: 110107.6562 - val_loss: 11816528896.0000 - val_rmse: 108216.3047\n",
      "Epoch 806/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12204774400.0000 - rmse: 109914.4453 - val_loss: 11803665408.0000 - val_rmse: 108157.2109\n",
      "Epoch 807/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12191952896.0000 - rmse: 109883.0469 - val_loss: 11790791680.0000 - val_rmse: 108098.0156\n",
      "Epoch 808/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 12179229696.0000 - rmse: 109886.7422 - val_loss: 11777846272.0000 - val_rmse: 108038.4766\n",
      "Epoch 809/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12166366208.0000 - rmse: 109760.0391 - val_loss: 11765477376.0000 - val_rmse: 107981.5391\n",
      "Epoch 810/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12153596928.0000 - rmse: 109835.2344 - val_loss: 11752625152.0000 - val_rmse: 107922.3750\n",
      "Epoch 811/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12140764160.0000 - rmse: 109677.3125 - val_loss: 11740037120.0000 - val_rmse: 107864.3516\n",
      "Epoch 812/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12128055296.0000 - rmse: 109607.6797 - val_loss: 11727632384.0000 - val_rmse: 107807.2109\n",
      "Epoch 813/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12115226624.0000 - rmse: 109656.1094 - val_loss: 11714500608.0000 - val_rmse: 107746.6328\n",
      "Epoch 814/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12102516736.0000 - rmse: 109448.0938 - val_loss: 11702240256.0000 - val_rmse: 107690.0703\n",
      "Epoch 815/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12089725952.0000 - rmse: 109321.4219 - val_loss: 11689332736.0000 - val_rmse: 107630.4766\n",
      "Epoch 816/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 12076986368.0000 - rmse: 109402.6016 - val_loss: 11676869632.0000 - val_rmse: 107572.9531\n",
      "Epoch 817/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12064248832.0000 - rmse: 109345.5938 - val_loss: 11664146432.0000 - val_rmse: 107514.1328\n",
      "Epoch 818/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12051503104.0000 - rmse: 109267.3828 - val_loss: 11651523584.0000 - val_rmse: 107455.7656\n",
      "Epoch 819/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12038792192.0000 - rmse: 109224.3125 - val_loss: 11638651904.0000 - val_rmse: 107396.2422\n",
      "Epoch 820/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 12026047488.0000 - rmse: 109025.5781 - val_loss: 11626081280.0000 - val_rmse: 107338.0234\n",
      "Epoch 821/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12013263872.0000 - rmse: 109210.2422 - val_loss: 11613594624.0000 - val_rmse: 107280.1953\n",
      "Epoch 822/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 12000525312.0000 - rmse: 108908.3906 - val_loss: 11600825344.0000 - val_rmse: 107221.0469\n",
      "Epoch 823/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11987787776.0000 - rmse: 109063.8516 - val_loss: 11587952640.0000 - val_rmse: 107161.3516\n",
      "Epoch 824/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11975041024.0000 - rmse: 108824.2031 - val_loss: 11575553024.0000 - val_rmse: 107103.8438\n",
      "Epoch 825/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11962342400.0000 - rmse: 108707.8906 - val_loss: 11562681344.0000 - val_rmse: 107044.0859\n",
      "Epoch 826/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11949619200.0000 - rmse: 108765.0547 - val_loss: 11550295040.0000 - val_rmse: 106986.5391\n",
      "Epoch 827/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 11936864256.0000 - rmse: 108738.5000 - val_loss: 11537353728.0000 - val_rmse: 106926.3906\n",
      "Epoch 828/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11924128768.0000 - rmse: 108778.6406 - val_loss: 11525214208.0000 - val_rmse: 106869.9844\n",
      "Epoch 829/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11911345152.0000 - rmse: 108663.7422 - val_loss: 11512107008.0000 - val_rmse: 106808.9844\n",
      "Epoch 830/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11898573824.0000 - rmse: 108480.2734 - val_loss: 11499572224.0000 - val_rmse: 106750.6484\n",
      "Epoch 831/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11885831168.0000 - rmse: 108409.8828 - val_loss: 11487046656.0000 - val_rmse: 106692.3516\n",
      "Epoch 832/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11873052672.0000 - rmse: 108342.8672 - val_loss: 11474506752.0000 - val_rmse: 106633.9531\n",
      "Epoch 833/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11860257792.0000 - rmse: 108340.1484 - val_loss: 11461625856.0000 - val_rmse: 106573.9141\n",
      "Epoch 834/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11847492608.0000 - rmse: 108273.0391 - val_loss: 11448903680.0000 - val_rmse: 106514.5859\n",
      "Epoch 835/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11834732544.0000 - rmse: 108382.5938 - val_loss: 11436284928.0000 - val_rmse: 106455.7344\n",
      "Epoch 836/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11821957120.0000 - rmse: 108215.9375 - val_loss: 11423559680.0000 - val_rmse: 106396.3203\n",
      "Epoch 837/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11809234944.0000 - rmse: 108088.6016 - val_loss: 11410843648.0000 - val_rmse: 106336.9297\n",
      "Epoch 838/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11796487168.0000 - rmse: 108110.1797 - val_loss: 11397957632.0000 - val_rmse: 106276.7188\n",
      "Epoch 839/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11783724032.0000 - rmse: 107951.4375 - val_loss: 11385517056.0000 - val_rmse: 106218.5469\n",
      "Epoch 840/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11770897408.0000 - rmse: 107992.5312 - val_loss: 11372923904.0000 - val_rmse: 106159.6484\n",
      "Epoch 841/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11758153728.0000 - rmse: 107936.9531 - val_loss: 11360139264.0000 - val_rmse: 106099.8203\n",
      "Epoch 842/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11745404928.0000 - rmse: 108023.8203 - val_loss: 11347503104.0000 - val_rmse: 106040.6328\n",
      "Epoch 843/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11732702208.0000 - rmse: 107858.1797 - val_loss: 11334856704.0000 - val_rmse: 105981.4062\n",
      "Epoch 844/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11719930880.0000 - rmse: 107720.9375 - val_loss: 11322252288.0000 - val_rmse: 105922.3047\n",
      "Epoch 845/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11707196416.0000 - rmse: 107681.7109 - val_loss: 11309638656.0000 - val_rmse: 105863.1484\n",
      "Epoch 846/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11694437376.0000 - rmse: 107654.3359 - val_loss: 11296526336.0000 - val_rmse: 105801.6328\n",
      "Epoch 847/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11681644544.0000 - rmse: 107555.9375 - val_loss: 11284091904.0000 - val_rmse: 105743.2344\n",
      "Epoch 848/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11668884480.0000 - rmse: 107422.2812 - val_loss: 11271454720.0000 - val_rmse: 105683.8906\n",
      "Epoch 849/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11656168448.0000 - rmse: 107437.7266 - val_loss: 11258869760.0000 - val_rmse: 105624.7109\n",
      "Epoch 850/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11643365376.0000 - rmse: 107370.2734 - val_loss: 11245825024.0000 - val_rmse: 105563.3750\n",
      "Epoch 851/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11630533632.0000 - rmse: 107427.5469 - val_loss: 11233457152.0000 - val_rmse: 105505.1719\n",
      "Epoch 852/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11617736704.0000 - rmse: 107157.6875 - val_loss: 11220545536.0000 - val_rmse: 105444.3516\n",
      "Epoch 853/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11604923392.0000 - rmse: 107246.3672 - val_loss: 11207865344.0000 - val_rmse: 105384.6250\n",
      "Epoch 854/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11592158208.0000 - rmse: 107166.8906 - val_loss: 11195089920.0000 - val_rmse: 105324.4062\n",
      "Epoch 855/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11579366400.0000 - rmse: 107084.7578 - val_loss: 11182410752.0000 - val_rmse: 105264.5703\n",
      "Epoch 856/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11566610432.0000 - rmse: 107041.6953 - val_loss: 11169937408.0000 - val_rmse: 105205.6953\n",
      "Epoch 857/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11553784832.0000 - rmse: 106919.7969 - val_loss: 11157014528.0000 - val_rmse: 105144.6250\n",
      "Epoch 858/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11540974592.0000 - rmse: 106809.9922 - val_loss: 11144345600.0000 - val_rmse: 105084.7578\n",
      "Epoch 859/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11528102912.0000 - rmse: 106901.5625 - val_loss: 11131606016.0000 - val_rmse: 105024.5156\n",
      "Epoch 860/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11515248640.0000 - rmse: 106739.9141 - val_loss: 11118770176.0000 - val_rmse: 104963.7891\n",
      "Epoch 861/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11502457856.0000 - rmse: 106585.6953 - val_loss: 11105709056.0000 - val_rmse: 104902.0000\n",
      "Epoch 862/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11489590272.0000 - rmse: 106657.9531 - val_loss: 11093551104.0000 - val_rmse: 104844.4062\n",
      "Epoch 863/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11476698112.0000 - rmse: 106543.5156 - val_loss: 11080674304.0000 - val_rmse: 104783.3672\n",
      "Epoch 864/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11463878656.0000 - rmse: 106485.9062 - val_loss: 11068110848.0000 - val_rmse: 104723.7812\n",
      "Epoch 865/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11451123712.0000 - rmse: 106541.5938 - val_loss: 11055563776.0000 - val_rmse: 104664.2344\n",
      "Epoch 866/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11438289920.0000 - rmse: 106289.2812 - val_loss: 11042455552.0000 - val_rmse: 104601.9844\n",
      "Epoch 867/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11425467392.0000 - rmse: 106386.7266 - val_loss: 11029929984.0000 - val_rmse: 104542.4766\n",
      "Epoch 868/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11412683776.0000 - rmse: 106320.8359 - val_loss: 11017275392.0000 - val_rmse: 104482.3047\n",
      "Epoch 869/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11399855104.0000 - rmse: 106180.8672 - val_loss: 11004334080.0000 - val_rmse: 104420.7344\n",
      "Epoch 870/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11387049984.0000 - rmse: 106160.7266 - val_loss: 10991830016.0000 - val_rmse: 104361.2344\n",
      "Epoch 871/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11374240768.0000 - rmse: 106150.8906 - val_loss: 10979369984.0000 - val_rmse: 104301.8906\n",
      "Epoch 872/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11361441792.0000 - rmse: 105931.5625 - val_loss: 10966532096.0000 - val_rmse: 104240.7344\n",
      "Epoch 873/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11348697088.0000 - rmse: 105989.8906 - val_loss: 10954053632.0000 - val_rmse: 104181.2188\n",
      "Epoch 874/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11335911424.0000 - rmse: 105878.5312 - val_loss: 10941303808.0000 - val_rmse: 104120.3906\n",
      "Epoch 875/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11323119616.0000 - rmse: 105850.7891 - val_loss: 10928644096.0000 - val_rmse: 104059.9766\n",
      "Epoch 876/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11310344192.0000 - rmse: 105939.4375 - val_loss: 10916009984.0000 - val_rmse: 103999.6094\n",
      "Epoch 877/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11297560576.0000 - rmse: 105737.4609 - val_loss: 10903254016.0000 - val_rmse: 103938.6719\n",
      "Epoch 878/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11284782080.0000 - rmse: 105764.8672 - val_loss: 10890590208.0000 - val_rmse: 103878.1328\n",
      "Epoch 879/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11271962624.0000 - rmse: 105559.7031 - val_loss: 10877394944.0000 - val_rmse: 103815.0156\n",
      "Epoch 880/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11259169792.0000 - rmse: 105562.2891 - val_loss: 10865172480.0000 - val_rmse: 103756.4766\n",
      "Epoch 881/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11246368768.0000 - rmse: 105593.5156 - val_loss: 10852738048.0000 - val_rmse: 103696.9297\n",
      "Epoch 882/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11233590272.0000 - rmse: 105377.2812 - val_loss: 10840085504.0000 - val_rmse: 103636.2656\n",
      "Epoch 883/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11220843520.0000 - rmse: 105362.0234 - val_loss: 10827139072.0000 - val_rmse: 103574.1953\n",
      "Epoch 884/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11208028160.0000 - rmse: 105280.4062 - val_loss: 10814983168.0000 - val_rmse: 103515.8516\n",
      "Epoch 885/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11195236352.0000 - rmse: 105263.0781 - val_loss: 10801999872.0000 - val_rmse: 103453.4766\n",
      "Epoch 886/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11182483456.0000 - rmse: 105185.4219 - val_loss: 10789479424.0000 - val_rmse: 103393.3438\n",
      "Epoch 887/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11169623040.0000 - rmse: 105072.6484 - val_loss: 10776808448.0000 - val_rmse: 103332.4375\n",
      "Epoch 888/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11156829184.0000 - rmse: 105053.1094 - val_loss: 10764115968.0000 - val_rmse: 103271.4062\n",
      "Epoch 889/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11144024064.0000 - rmse: 105046.1641 - val_loss: 10751492096.0000 - val_rmse: 103210.6250\n",
      "Epoch 890/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 11131199488.0000 - rmse: 104850.4297 - val_loss: 10738817024.0000 - val_rmse: 103149.5938\n",
      "Epoch 891/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11118303232.0000 - rmse: 104950.1875 - val_loss: 10726169600.0000 - val_rmse: 103088.6484\n",
      "Epoch 892/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11105550336.0000 - rmse: 104830.7031 - val_loss: 10713625600.0000 - val_rmse: 103028.1719\n",
      "Epoch 893/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11092792320.0000 - rmse: 104811.2578 - val_loss: 10700805120.0000 - val_rmse: 102966.3281\n",
      "Epoch 894/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11079885824.0000 - rmse: 104819.5547 - val_loss: 10688076800.0000 - val_rmse: 102904.9062\n",
      "Epoch 895/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11067090944.0000 - rmse: 104636.1328 - val_loss: 10675468288.0000 - val_rmse: 102843.9844\n",
      "Epoch 896/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 11054288896.0000 - rmse: 104543.4688 - val_loss: 10663036928.0000 - val_rmse: 102783.8750\n",
      "Epoch 897/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11041443840.0000 - rmse: 104450.5703 - val_loss: 10650545152.0000 - val_rmse: 102723.5156\n",
      "Epoch 898/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11028606976.0000 - rmse: 104558.1562 - val_loss: 10637899776.0000 - val_rmse: 102662.3438\n",
      "Epoch 899/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11015813120.0000 - rmse: 104466.7812 - val_loss: 10624848896.0000 - val_rmse: 102599.1719\n",
      "Epoch 900/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 11002997760.0000 - rmse: 104397.1641 - val_loss: 10612481024.0000 - val_rmse: 102539.3047\n",
      "Epoch 901/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10990166016.0000 - rmse: 104321.7344 - val_loss: 10599714816.0000 - val_rmse: 102477.4141\n",
      "Epoch 902/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10977371136.0000 - rmse: 104274.4375 - val_loss: 10587309056.0000 - val_rmse: 102417.2422\n",
      "Epoch 903/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10964551680.0000 - rmse: 104205.2812 - val_loss: 10574600192.0000 - val_rmse: 102355.6328\n",
      "Epoch 904/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10951785472.0000 - rmse: 104101.0078 - val_loss: 10562166784.0000 - val_rmse: 102295.3047\n",
      "Epoch 905/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10938907648.0000 - rmse: 104150.4688 - val_loss: 10549248000.0000 - val_rmse: 102232.5391\n",
      "Epoch 906/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10926075904.0000 - rmse: 104023.5625 - val_loss: 10536607744.0000 - val_rmse: 102171.0859\n",
      "Epoch 907/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10913243136.0000 - rmse: 103818.4531 - val_loss: 10524082176.0000 - val_rmse: 102110.1875\n",
      "Epoch 908/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10900361216.0000 - rmse: 103869.0312 - val_loss: 10511318016.0000 - val_rmse: 102048.0703\n",
      "Epoch 909/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10887515136.0000 - rmse: 103710.0703 - val_loss: 10498655232.0000 - val_rmse: 101986.4297\n",
      "Epoch 910/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10874606592.0000 - rmse: 103869.3828 - val_loss: 10485872640.0000 - val_rmse: 101924.1250\n",
      "Epoch 911/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10861757440.0000 - rmse: 103679.8516 - val_loss: 10473199616.0000 - val_rmse: 101862.3281\n",
      "Epoch 912/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10848902144.0000 - rmse: 103484.0781 - val_loss: 10460203008.0000 - val_rmse: 101798.9531\n",
      "Epoch 913/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10836057088.0000 - rmse: 103520.5312 - val_loss: 10447876096.0000 - val_rmse: 101738.7891\n",
      "Epoch 914/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10823284736.0000 - rmse: 103476.6797 - val_loss: 10435235840.0000 - val_rmse: 101677.0391\n",
      "Epoch 915/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10810455040.0000 - rmse: 103479.3594 - val_loss: 10422335488.0000 - val_rmse: 101614.0000\n",
      "Epoch 916/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10797605888.0000 - rmse: 103501.2188 - val_loss: 10409790464.0000 - val_rmse: 101552.6016\n",
      "Epoch 917/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10784731136.0000 - rmse: 103359.9844 - val_loss: 10397248512.0000 - val_rmse: 101491.2578\n",
      "Epoch 918/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10771927040.0000 - rmse: 103314.9688 - val_loss: 10384410624.0000 - val_rmse: 101428.3750\n",
      "Epoch 919/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10759020544.0000 - rmse: 103326.3047 - val_loss: 10371809280.0000 - val_rmse: 101366.6328\n",
      "Epoch 920/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10746128384.0000 - rmse: 103154.2266 - val_loss: 10358942720.0000 - val_rmse: 101303.5391\n",
      "Epoch 921/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10733324288.0000 - rmse: 103030.7812 - val_loss: 10346533888.0000 - val_rmse: 101242.6641\n",
      "Epoch 922/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10720348160.0000 - rmse: 103078.4062 - val_loss: 10333452288.0000 - val_rmse: 101178.4219\n",
      "Epoch 923/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10707479552.0000 - rmse: 102894.8125 - val_loss: 10320918528.0000 - val_rmse: 101116.8672\n",
      "Epoch 924/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10694572032.0000 - rmse: 102958.3828 - val_loss: 10308200448.0000 - val_rmse: 101054.2969\n",
      "Epoch 925/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 10681670656.0000 - rmse: 102778.7109 - val_loss: 10295537664.0000 - val_rmse: 100991.9844\n",
      "Epoch 926/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10668791808.0000 - rmse: 102713.3281 - val_loss: 10282359808.0000 - val_rmse: 100927.1562\n",
      "Epoch 927/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10655847424.0000 - rmse: 102633.9062 - val_loss: 10269950976.0000 - val_rmse: 100866.0078\n",
      "Epoch 928/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10642979840.0000 - rmse: 102481.1641 - val_loss: 10257393664.0000 - val_rmse: 100804.1094\n",
      "Epoch 929/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 10630164480.0000 - rmse: 102554.0469 - val_loss: 10244696064.0000 - val_rmse: 100741.4766\n",
      "Epoch 930/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10617225216.0000 - rmse: 102566.6641 - val_loss: 10232006656.0000 - val_rmse: 100678.8281\n",
      "Epoch 931/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10604365824.0000 - rmse: 102427.0000 - val_loss: 10219544576.0000 - val_rmse: 100617.2969\n",
      "Epoch 932/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10591556608.0000 - rmse: 102420.5859 - val_loss: 10207020032.0000 - val_rmse: 100555.4219\n",
      "Epoch 933/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10578727936.0000 - rmse: 102335.2656 - val_loss: 10194199552.0000 - val_rmse: 100492.0312\n",
      "Epoch 934/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10565842944.0000 - rmse: 102381.0703 - val_loss: 10181529600.0000 - val_rmse: 100429.3438\n",
      "Epoch 935/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10553056256.0000 - rmse: 102147.1328 - val_loss: 10168833024.0000 - val_rmse: 100366.5078\n",
      "Epoch 936/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10540204032.0000 - rmse: 102189.2656 - val_loss: 10156473344.0000 - val_rmse: 100305.2656\n",
      "Epoch 937/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10527348736.0000 - rmse: 102122.5547 - val_loss: 10143813632.0000 - val_rmse: 100242.5391\n",
      "Epoch 938/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10514531328.0000 - rmse: 101964.9297 - val_loss: 10131102720.0000 - val_rmse: 100179.4766\n",
      "Epoch 939/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10501788672.0000 - rmse: 102007.5547 - val_loss: 10118303744.0000 - val_rmse: 100115.9766\n",
      "Epoch 940/1000\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 10488992768.0000 - rmse: 101891.1797 - val_loss: 10105819136.0000 - val_rmse: 100053.9688\n",
      "Epoch 941/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10476135424.0000 - rmse: 101787.0859 - val_loss: 10093208576.0000 - val_rmse: 99991.3203\n",
      "Epoch 942/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10463351808.0000 - rmse: 101757.9453 - val_loss: 10080622592.0000 - val_rmse: 99928.7578\n",
      "Epoch 943/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10450515968.0000 - rmse: 101658.0156 - val_loss: 10067713024.0000 - val_rmse: 99864.5391\n",
      "Epoch 944/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10437657600.0000 - rmse: 101774.1953 - val_loss: 10055201792.0000 - val_rmse: 99802.2344\n",
      "Epoch 945/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10424795136.0000 - rmse: 101614.6797 - val_loss: 10042690560.0000 - val_rmse: 99739.9609\n",
      "Epoch 946/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10412000256.0000 - rmse: 101526.1797 - val_loss: 10030096384.0000 - val_rmse: 99677.1797\n",
      "Epoch 947/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10399204352.0000 - rmse: 101331.8594 - val_loss: 10017514496.0000 - val_rmse: 99614.4531\n",
      "Epoch 948/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10386393088.0000 - rmse: 101414.0781 - val_loss: 10004915200.0000 - val_rmse: 99551.5703\n",
      "Epoch 949/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10373602304.0000 - rmse: 101339.0703 - val_loss: 9992327168.0000 - val_rmse: 99488.7109\n",
      "Epoch 950/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10360873984.0000 - rmse: 101257.7109 - val_loss: 9979705344.0000 - val_rmse: 99425.6719\n",
      "Epoch 951/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10348100608.0000 - rmse: 101194.1094 - val_loss: 9967102976.0000 - val_rmse: 99362.6641\n",
      "Epoch 952/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10335321088.0000 - rmse: 101153.1719 - val_loss: 9954414592.0000 - val_rmse: 99299.1953\n",
      "Epoch 953/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10322545664.0000 - rmse: 101044.2578 - val_loss: 9942111232.0000 - val_rmse: 99237.5938\n",
      "Epoch 954/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10309789696.0000 - rmse: 101037.8359 - val_loss: 9929390080.0000 - val_rmse: 99173.8750\n",
      "Epoch 955/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 10297035776.0000 - rmse: 100903.5078 - val_loss: 9916783616.0000 - val_rmse: 99110.6953\n",
      "Epoch 956/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10284184576.0000 - rmse: 100916.8203 - val_loss: 9904306176.0000 - val_rmse: 99048.0703\n",
      "Epoch 957/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10271335424.0000 - rmse: 100879.2969 - val_loss: 9891736576.0000 - val_rmse: 98984.9844\n",
      "Epoch 958/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10258565120.0000 - rmse: 100746.6016 - val_loss: 9878704128.0000 - val_rmse: 98919.5625\n",
      "Epoch 959/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10245672960.0000 - rmse: 100756.9141 - val_loss: 9866250240.0000 - val_rmse: 98856.9531\n",
      "Epoch 960/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10232827904.0000 - rmse: 100554.8906 - val_loss: 9853704192.0000 - val_rmse: 98793.8594\n",
      "Epoch 961/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10219993088.0000 - rmse: 100445.9844 - val_loss: 9840900096.0000 - val_rmse: 98729.4375\n",
      "Epoch 962/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10207219712.0000 - rmse: 100491.0625 - val_loss: 9828435968.0000 - val_rmse: 98666.6719\n",
      "Epoch 963/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10194328576.0000 - rmse: 100335.5781 - val_loss: 9815898112.0000 - val_rmse: 98603.4688\n",
      "Epoch 964/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10181508096.0000 - rmse: 100514.9922 - val_loss: 9803308032.0000 - val_rmse: 98539.9766\n",
      "Epoch 965/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10168663040.0000 - rmse: 100345.5391 - val_loss: 9790720000.0000 - val_rmse: 98476.4766\n",
      "Epoch 966/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10155776000.0000 - rmse: 100110.4375 - val_loss: 9778177024.0000 - val_rmse: 98413.1172\n",
      "Epoch 967/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10142927872.0000 - rmse: 100190.6641 - val_loss: 9765381120.0000 - val_rmse: 98348.4688\n",
      "Epoch 968/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10130068480.0000 - rmse: 100088.1719 - val_loss: 9753235456.0000 - val_rmse: 98287.0547\n",
      "Epoch 969/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10117254144.0000 - rmse: 99938.1953 - val_loss: 9740657664.0000 - val_rmse: 98223.4062\n",
      "Epoch 970/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10104380416.0000 - rmse: 100041.5625 - val_loss: 9728196608.0000 - val_rmse: 98160.3203\n",
      "Epoch 971/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10091560960.0000 - rmse: 99965.3984 - val_loss: 9715731456.0000 - val_rmse: 98097.2031\n",
      "Epoch 972/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10078668800.0000 - rmse: 99974.0859 - val_loss: 9703058432.0000 - val_rmse: 98032.9531\n",
      "Epoch 973/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10065831936.0000 - rmse: 99822.9531 - val_loss: 9690681344.0000 - val_rmse: 97970.1797\n",
      "Epoch 974/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10052957184.0000 - rmse: 99770.3516 - val_loss: 9678113792.0000 - val_rmse: 97906.3672\n",
      "Epoch 975/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10040105984.0000 - rmse: 99608.9609 - val_loss: 9665685504.0000 - val_rmse: 97843.2734\n",
      "Epoch 976/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 10027271168.0000 - rmse: 99612.9375 - val_loss: 9653049344.0000 - val_rmse: 97779.0625\n",
      "Epoch 977/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10014477312.0000 - rmse: 99442.6875 - val_loss: 9640705024.0000 - val_rmse: 97716.2812\n",
      "Epoch 978/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 10001645568.0000 - rmse: 99490.7344 - val_loss: 9628065792.0000 - val_rmse: 97651.9531\n",
      "Epoch 979/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 9988806656.0000 - rmse: 99364.4766 - val_loss: 9615578112.0000 - val_rmse: 97588.3984\n",
      "Epoch 980/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 9976002560.0000 - rmse: 99330.7344 - val_loss: 9603136512.0000 - val_rmse: 97525.0234\n",
      "Epoch 981/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9963197440.0000 - rmse: 99289.8281 - val_loss: 9590512640.0000 - val_rmse: 97460.6641\n",
      "Epoch 982/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 9950366720.0000 - rmse: 99296.1328 - val_loss: 9578166272.0000 - val_rmse: 97397.6953\n",
      "Epoch 983/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9937525760.0000 - rmse: 99190.4609 - val_loss: 9565847552.0000 - val_rmse: 97334.7969\n",
      "Epoch 984/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9924748288.0000 - rmse: 98984.1016 - val_loss: 9553381376.0000 - val_rmse: 97271.1484\n",
      "Epoch 985/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9911969792.0000 - rmse: 98943.1875 - val_loss: 9540710400.0000 - val_rmse: 97206.4219\n",
      "Epoch 986/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 9899118592.0000 - rmse: 99045.1719 - val_loss: 9528423424.0000 - val_rmse: 97143.5469\n",
      "Epoch 987/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9886247936.0000 - rmse: 98977.6641 - val_loss: 9515875328.0000 - val_rmse: 97079.3359\n",
      "Epoch 988/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9873430528.0000 - rmse: 98786.0625 - val_loss: 9503441920.0000 - val_rmse: 97015.6562\n",
      "Epoch 989/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9860621312.0000 - rmse: 98741.5234 - val_loss: 9490765824.0000 - val_rmse: 96950.6875\n",
      "Epoch 990/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9847776256.0000 - rmse: 98734.6953 - val_loss: 9478331392.0000 - val_rmse: 96886.9375\n",
      "Epoch 991/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 9834916864.0000 - rmse: 98567.9141 - val_loss: 9465930752.0000 - val_rmse: 96823.3281\n",
      "Epoch 992/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9822086144.0000 - rmse: 98609.7891 - val_loss: 9453449216.0000 - val_rmse: 96759.2031\n",
      "Epoch 993/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9809233920.0000 - rmse: 98423.7031 - val_loss: 9441018880.0000 - val_rmse: 96695.3359\n",
      "Epoch 994/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9796361216.0000 - rmse: 98492.5547 - val_loss: 9428489216.0000 - val_rmse: 96630.9219\n",
      "Epoch 995/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9783534592.0000 - rmse: 98390.2969 - val_loss: 9416161280.0000 - val_rmse: 96567.4688\n",
      "Epoch 996/1000\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 9770696704.0000 - rmse: 98350.3047 - val_loss: 9403692032.0000 - val_rmse: 96503.2656\n",
      "Epoch 997/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9757783040.0000 - rmse: 98301.4141 - val_loss: 9391323136.0000 - val_rmse: 96439.5625\n",
      "Epoch 998/1000\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 9744920576.0000 - rmse: 98254.4844 - val_loss: 9379044352.0000 - val_rmse: 96376.2344\n",
      "Epoch 999/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 9732040704.0000 - rmse: 98039.4609 - val_loss: 9366384640.0000 - val_rmse: 96310.8828\n",
      "Epoch 1000/1000\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 9719168000.0000 - rmse: 97967.9922 - val_loss: 9354059776.0000 - val_rmse: 96247.2656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;keras&#x27;,\n",
       "                 KerasRegressor(batch_size=100, callbacks=[&lt;keras.src.callbacks.EarlyStopping object at 0x7e2ab83b37f0&gt;], epochs=1000, model=&lt;keras.src.engine.sequential.Sequential object at 0x7e2acc4f5900&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;keras&#x27;,\n",
       "                 KerasRegressor(batch_size=100, callbacks=[&lt;keras.src.callbacks.EarlyStopping object at 0x7e2ab83b37f0&gt;], epochs=1000, model=&lt;keras.src.engine.sequential.Sequential object at 0x7e2acc4f5900&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;keras.src.engine.sequential.Sequential object at 0x7e2acc4f5900&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=100\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.src.callbacks.EarlyStopping object at 0x7e2ab83b37f0&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1000\n",
       ")</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('keras',\n",
       "                 KerasRegressor(batch_size=100, callbacks=[<keras.src.callbacks.EarlyStopping object at 0x7e2ab83b37f0>], epochs=1000, model=<keras.src.engine.sequential.Sequential object at 0x7e2acc4f5900>))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([])\n",
    "pipe.steps.append((\"scaler\", StandardScaler()))\n",
    "\n",
    "pipe.fit(X_train)\n",
    "X_test_transformed = pipe.transform(X_test)\n",
    "\n",
    "keras_reg = build_keras_regressor(build_model(len(X_train.columns), [10]), patience=20, epochs=1000, verbose=1)\n",
    "pipe.steps.append((\"keras\", keras_reg))\n",
    "\n",
    "pipe.fit(X_train, y_train, keras__validation_data=(X_test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = pipe.named_steps['keras'].history_\n",
    "plot_rmse(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96716.38835555186"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "metrics.root_mean_squared_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
