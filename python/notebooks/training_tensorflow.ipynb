{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.14.0 in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.14.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
      "Requirement already satisfied: urllib3>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikeras==0.12.0 in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
      "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.11/dist-packages (from scikeras==0.12.0) (23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikeras==0.12.0) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikeras==0.12.0) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikeras==0.12.0) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikeras==0.12.0) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikeras==0.12.0) (3.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: cartopy in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (1.26.0)\n",
      "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.8.0)\n",
      "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.4)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from cartopy) (23.1)\n",
      "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
      "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->cartopy) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->cartopy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->cartopy) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->cartopy) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.5->cartopy) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow==2.14.0\n",
    "!pip3 install scikeras==0.12.0\n",
    "!pip3 install pandas\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 00:31:34.745719: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-01 00:31:34.745761: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-01 00:31:34.745788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-01 00:31:34.754377: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "if not gpu:\n",
    "    print(\"No GPU was detected\")\n",
    "else:\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/tf/notebooks/data/train.csv\")\n",
    "df_test = pd.read_csv(\"/tf/notebooks/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, quantile=0.05):\n",
    "    Q1 = df.quantile(quantile)\n",
    "    Q3 = df.quantile(1-quantile)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    return df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "def apply_feature_engineering(df: pd.DataFrame, keep_outliers) -> pd.DataFrame:\n",
    "    df[\"total_bedrooms\"] = df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].mean())\n",
    "    custom_encoding = {\"ISLAND\": 4, \"NEAR OCEAN\": 3, \"NEAR BAY\": 2, \"<1H OCEAN\": 1, \"INLAND\": 0}\n",
    "    df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n",
    "    df = df.drop(\"ocean_proximity\", axis=1)\n",
    "    df[\"rooms_per_bedroom\"] = df[\"total_rooms\"] / df[\"total_bedrooms\"]\n",
    "    df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]\n",
    "    df[\"encoded_position\"] = df[\"longitude\"] + df[\"latitude\"]\n",
    "    df[\"population_per_bedrooms\"] = df[\"population\"] / df[\"total_bedrooms\"]\n",
    "    df[\"target\"] = df[\"median_house_value\"]\n",
    "    df = df.drop(\"median_house_value\", axis=1)\n",
    "    if not keep_outliers:\n",
    "        df = remove_outliers(df, 0.05)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8541/285434561.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n",
      "/tmp/ipykernel_8541/285434561.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ocean_proximity_enc\"] = df.replace({\"ocean_proximity\": custom_encoding})[\"ocean_proximity\"]\n"
     ]
    }
   ],
   "source": [
    "df_train = apply_feature_engineering(df_train, True)\n",
    "df_test = apply_feature_engineering(df_test, False)\n",
    "\n",
    "X_train = df_train.drop(\"target\", axis=1)\n",
    "y_train = df_train[\"target\"]\n",
    "\n",
    "X_test = df_test.drop(\"target\", axis=1)\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69086.5477912973"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([])\n",
    "pipe.steps.append((\"scaler\", StandardScaler()))\n",
    "pipe.steps.append((\"reg\", LinearRegression()))\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_predict = pipe.predict(X_test)\n",
    "metrics.root_mean_squared_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmse(history):\n",
    "    loss = np.sqrt(history[\"loss\"])\n",
    "    val_loss = np.sqrt(history[\"val_loss\"])\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "    plt.plot(loss, label=\"Training\")\n",
    "    plt.plot(val_loss, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.math.square(y_pred - y_true))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs: int,\n",
    "                layers: list[int],\n",
    "                layers_per_dropout: int = 0,\n",
    "                dropout_rate: float = 0.0,\n",
    "                activation_func = \"relu\",\n",
    "                loss_func = \"mean_squared_error\",\n",
    "                optimizer = \"adam\"):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input((inputs, )))\n",
    "    count = 0\n",
    "    for n_nodes in layers:\n",
    "        model.add(Dense(n_nodes, activation=activation_func))\n",
    "        count += 1\n",
    "        if layers_per_dropout == count:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            count == 0\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss_func, metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "def build_keras_regressor(model,\n",
    "                          epochs = 100,\n",
    "                          batch_size = 100,\n",
    "                          verbose = 0,\n",
    "                          patience = None):\n",
    "    if patience is not None:\n",
    "        early_stop = EarlyStopping(patience = patience, restore_best_weights = True)\n",
    "        callbacks = [early_stop]\n",
    "    else:\n",
    "        callbacks = []\n",
    "    return KerasRegressor(model=model,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=verbose,\n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 00:31:37.591699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 00:31:41.361794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b548937b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-01 00:31:41.361823: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-05-01 00:31:41.368385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-01 00:31:41.541523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-05-01 00:31:41.666579: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 11s 8ms/step - loss: 12786080768.0000 - rmse: 97236.4453 - val_loss: 4840344576.0000 - val_rmse: 66561.9766\n",
      "Epoch 2/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4690845184.0000 - rmse: 65846.9219 - val_loss: 4480223232.0000 - val_rmse: 63960.0781\n",
      "Epoch 3/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4508477952.0000 - rmse: 64490.0859 - val_loss: 4310475776.0000 - val_rmse: 62730.3320\n",
      "Epoch 4/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4342581248.0000 - rmse: 63174.8203 - val_loss: 4294501888.0000 - val_rmse: 62593.2852\n",
      "Epoch 5/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4294937088.0000 - rmse: 63071.0117 - val_loss: 4134351360.0000 - val_rmse: 61533.0742\n",
      "Epoch 6/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4243166208.0000 - rmse: 62571.6680 - val_loss: 4197632000.0000 - val_rmse: 62128.6797\n",
      "Epoch 7/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4166809600.0000 - rmse: 62005.7383 - val_loss: 4055830528.0000 - val_rmse: 60758.0039\n",
      "Epoch 8/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4107212544.0000 - rmse: 61535.0039 - val_loss: 4230385408.0000 - val_rmse: 62337.7852\n",
      "Epoch 9/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4043326208.0000 - rmse: 61072.6211 - val_loss: 4053242368.0000 - val_rmse: 60872.2891\n",
      "Epoch 10/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 4060668416.0000 - rmse: 61190.6992 - val_loss: 3956645888.0000 - val_rmse: 60114.5312\n",
      "Epoch 11/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3965904384.0000 - rmse: 60507.0352 - val_loss: 3925869824.0000 - val_rmse: 59780.9727\n",
      "Epoch 12/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3893228288.0000 - rmse: 59882.2617 - val_loss: 3786187008.0000 - val_rmse: 58689.4180\n",
      "Epoch 13/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3833443072.0000 - rmse: 59564.1719 - val_loss: 3689703936.0000 - val_rmse: 58010.8359\n",
      "Epoch 14/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3815064832.0000 - rmse: 59258.4922 - val_loss: 3851641088.0000 - val_rmse: 59409.3320\n",
      "Epoch 15/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3814893312.0000 - rmse: 59149.3320 - val_loss: 3624119040.0000 - val_rmse: 57329.0234\n",
      "Epoch 16/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3763479040.0000 - rmse: 58855.4180 - val_loss: 3578072576.0000 - val_rmse: 56997.4141\n",
      "Epoch 17/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3678077696.0000 - rmse: 58019.1328 - val_loss: 3541896448.0000 - val_rmse: 56754.2422\n",
      "Epoch 18/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3665998080.0000 - rmse: 58128.3242 - val_loss: 3497518336.0000 - val_rmse: 56361.5234\n",
      "Epoch 19/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3602556160.0000 - rmse: 57660.6992 - val_loss: 3693579008.0000 - val_rmse: 57975.4570\n",
      "Epoch 20/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3534940672.0000 - rmse: 56847.1562 - val_loss: 3398724864.0000 - val_rmse: 55713.9922\n",
      "Epoch 21/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3515064576.0000 - rmse: 56881.3164 - val_loss: 3273319680.0000 - val_rmse: 54402.3398\n",
      "Epoch 22/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3529074432.0000 - rmse: 56880.8281 - val_loss: 3253560576.0000 - val_rmse: 54146.1250\n",
      "Epoch 23/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3440610560.0000 - rmse: 56241.6016 - val_loss: 3271986432.0000 - val_rmse: 54217.8711\n",
      "Epoch 24/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3380763392.0000 - rmse: 55549.3633 - val_loss: 3224685056.0000 - val_rmse: 53756.9219\n",
      "Epoch 25/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3387096832.0000 - rmse: 55559.9492 - val_loss: 3183779584.0000 - val_rmse: 53445.2461\n",
      "Epoch 26/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3385165312.0000 - rmse: 55757.4531 - val_loss: 3158855168.0000 - val_rmse: 53102.1992\n",
      "Epoch 27/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3409764352.0000 - rmse: 55744.0117 - val_loss: 3249980160.0000 - val_rmse: 54205.6094\n",
      "Epoch 28/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3335259136.0000 - rmse: 55251.0586 - val_loss: 3148879872.0000 - val_rmse: 53167.8398\n",
      "Epoch 29/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3343027200.0000 - rmse: 55349.8672 - val_loss: 3088140288.0000 - val_rmse: 52589.6250\n",
      "Epoch 30/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3341764864.0000 - rmse: 55263.2461 - val_loss: 3112609280.0000 - val_rmse: 52736.4961\n",
      "Epoch 31/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3292340736.0000 - rmse: 55106.0000 - val_loss: 3386593792.0000 - val_rmse: 55669.3086\n",
      "Epoch 32/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3289085440.0000 - rmse: 54758.8203 - val_loss: 3068713728.0000 - val_rmse: 52483.0039\n",
      "Epoch 33/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3295940608.0000 - rmse: 54976.9609 - val_loss: 3378301440.0000 - val_rmse: 54909.9688\n",
      "Epoch 34/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3265310976.0000 - rmse: 54566.9297 - val_loss: 3106908416.0000 - val_rmse: 52895.0898\n",
      "Epoch 35/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3254962176.0000 - rmse: 54495.8086 - val_loss: 3182584576.0000 - val_rmse: 53719.2109\n",
      "Epoch 36/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3287986176.0000 - rmse: 54721.0117 - val_loss: 3077623552.0000 - val_rmse: 52503.3086\n",
      "Epoch 37/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3201131520.0000 - rmse: 54010.1445 - val_loss: 3058515968.0000 - val_rmse: 52344.2070\n",
      "Epoch 38/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3205567232.0000 - rmse: 54260.8477 - val_loss: 3131214592.0000 - val_rmse: 53252.4336\n",
      "Epoch 39/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3212872192.0000 - rmse: 54208.0117 - val_loss: 3022804736.0000 - val_rmse: 52073.3086\n",
      "Epoch 40/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3224018688.0000 - rmse: 54138.7305 - val_loss: 3181445120.0000 - val_rmse: 53162.1562\n",
      "Epoch 41/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3198281728.0000 - rmse: 53964.8516 - val_loss: 3052071680.0000 - val_rmse: 52127.6250\n",
      "Epoch 42/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3206023424.0000 - rmse: 54205.7109 - val_loss: 3099965952.0000 - val_rmse: 52847.0469\n",
      "Epoch 43/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3190350848.0000 - rmse: 53940.1602 - val_loss: 3061174784.0000 - val_rmse: 52307.7070\n",
      "Epoch 44/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3164835328.0000 - rmse: 53785.9023 - val_loss: 3004916736.0000 - val_rmse: 51869.8945\n",
      "Epoch 45/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3140298752.0000 - rmse: 53543.8086 - val_loss: 3122366976.0000 - val_rmse: 52702.9609\n",
      "Epoch 46/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3143292160.0000 - rmse: 53537.4219 - val_loss: 3103825920.0000 - val_rmse: 52618.3281\n",
      "Epoch 47/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3102436608.0000 - rmse: 53203.9062 - val_loss: 2990267648.0000 - val_rmse: 51555.8945\n",
      "Epoch 48/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3159622656.0000 - rmse: 53561.5547 - val_loss: 2936507392.0000 - val_rmse: 51165.5898\n",
      "Epoch 49/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3141103616.0000 - rmse: 53495.1523 - val_loss: 2954092288.0000 - val_rmse: 51356.4766\n",
      "Epoch 50/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3091550208.0000 - rmse: 53190.1641 - val_loss: 2941518848.0000 - val_rmse: 51276.3281\n",
      "Epoch 51/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3091597056.0000 - rmse: 53278.0312 - val_loss: 2955308032.0000 - val_rmse: 51462.8867\n",
      "Epoch 52/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3054144512.0000 - rmse: 52777.6445 - val_loss: 3023352576.0000 - val_rmse: 52062.8555\n",
      "Epoch 53/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 3005520128.0000 - rmse: 52452.2344 - val_loss: 2918001920.0000 - val_rmse: 50770.8594\n",
      "Epoch 54/1000\n",
      "774/774 [==============================] - 7s 8ms/step - loss: 3055814912.0000 - rmse: 52809.3125 - val_loss: 2947927296.0000 - val_rmse: 51277.8555\n",
      "Epoch 55/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 2997524224.0000 - rmse: 52431.9141 - val_loss: 2944494848.0000 - val_rmse: 51069.6445\n",
      "Epoch 56/1000\n",
      "774/774 [==============================] - 6s 7ms/step - loss: 3031489024.0000 - rmse: 52592.7500 - val_loss: 2962407680.0000 - val_rmse: 51592.2031\n",
      "Epoch 57/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 3004741632.0000 - rmse: 52417.3945 - val_loss: 2963669760.0000 - val_rmse: 51555.5938\n",
      "Epoch 58/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 2987645440.0000 - rmse: 52220.4023 - val_loss: 3145453056.0000 - val_rmse: 53297.5547\n",
      "Epoch 59/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 2968199936.0000 - rmse: 51882.7461 - val_loss: 3033672704.0000 - val_rmse: 52295.6719\n",
      "Epoch 60/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 2992777472.0000 - rmse: 52302.0430 - val_loss: 2877377536.0000 - val_rmse: 50487.3164\n",
      "Epoch 61/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2971869696.0000 - rmse: 51941.4609 - val_loss: 2874941440.0000 - val_rmse: 50575.7695\n",
      "Epoch 62/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2965918976.0000 - rmse: 51845.2305 - val_loss: 2969751808.0000 - val_rmse: 51129.2656\n",
      "Epoch 63/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2924794880.0000 - rmse: 51606.7148 - val_loss: 2893821440.0000 - val_rmse: 50634.7852\n",
      "Epoch 64/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2879380992.0000 - rmse: 51380.2500 - val_loss: 2895252736.0000 - val_rmse: 50915.6367\n",
      "Epoch 65/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2882494464.0000 - rmse: 51235.4609 - val_loss: 2828823296.0000 - val_rmse: 50149.1016\n",
      "Epoch 66/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2882236672.0000 - rmse: 51211.7070 - val_loss: 2863920896.0000 - val_rmse: 50180.4766\n",
      "Epoch 67/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2877565184.0000 - rmse: 51278.2070 - val_loss: 2842694912.0000 - val_rmse: 50118.7031\n",
      "Epoch 68/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2863598336.0000 - rmse: 51174.8906 - val_loss: 2916183040.0000 - val_rmse: 50928.9648\n",
      "Epoch 69/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2855747840.0000 - rmse: 51093.9219 - val_loss: 2849312256.0000 - val_rmse: 50139.7695\n",
      "Epoch 70/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2799602688.0000 - rmse: 50421.7422 - val_loss: 2814796544.0000 - val_rmse: 49800.8750\n",
      "Epoch 71/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2842269952.0000 - rmse: 50733.4062 - val_loss: 2796004864.0000 - val_rmse: 49664.5469\n",
      "Epoch 72/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2801288192.0000 - rmse: 50533.5039 - val_loss: 3231804672.0000 - val_rmse: 53407.3867\n",
      "Epoch 73/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2805563392.0000 - rmse: 50465.2305 - val_loss: 2880568064.0000 - val_rmse: 50900.0312\n",
      "Epoch 74/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2830385920.0000 - rmse: 50844.0508 - val_loss: 2795226880.0000 - val_rmse: 49825.4414\n",
      "Epoch 75/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2784218624.0000 - rmse: 50432.2852 - val_loss: 2797108736.0000 - val_rmse: 50060.5547\n",
      "Epoch 76/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2787611904.0000 - rmse: 50400.6406 - val_loss: 2933379584.0000 - val_rmse: 51327.6797\n",
      "Epoch 77/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2772489472.0000 - rmse: 50198.4375 - val_loss: 2796760064.0000 - val_rmse: 49639.5469\n",
      "Epoch 78/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2793290240.0000 - rmse: 50481.9375 - val_loss: 2771172096.0000 - val_rmse: 49545.6758\n",
      "Epoch 79/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2728900096.0000 - rmse: 49765.3086 - val_loss: 2759286784.0000 - val_rmse: 49420.8281\n",
      "Epoch 80/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2759565312.0000 - rmse: 50118.4297 - val_loss: 2845114880.0000 - val_rmse: 49993.3984\n",
      "Epoch 81/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2765518336.0000 - rmse: 50066.3945 - val_loss: 2765074176.0000 - val_rmse: 49407.6250\n",
      "Epoch 82/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2749199360.0000 - rmse: 50061.6328 - val_loss: 2754372864.0000 - val_rmse: 49402.0039\n",
      "Epoch 83/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2734721280.0000 - rmse: 49899.8594 - val_loss: 2760205312.0000 - val_rmse: 49542.8359\n",
      "Epoch 84/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2768064512.0000 - rmse: 50262.6094 - val_loss: 2753391360.0000 - val_rmse: 49418.4102\n",
      "Epoch 85/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2706149376.0000 - rmse: 49632.8008 - val_loss: 2740112896.0000 - val_rmse: 49274.6562\n",
      "Epoch 86/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2717251840.0000 - rmse: 49745.2930 - val_loss: 2930974464.0000 - val_rmse: 50714.6836\n",
      "Epoch 87/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2718077440.0000 - rmse: 49690.3633 - val_loss: 2760682240.0000 - val_rmse: 49439.4492\n",
      "Epoch 88/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2711899648.0000 - rmse: 49696.6406 - val_loss: 2728081920.0000 - val_rmse: 49014.9336\n",
      "Epoch 89/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2697939712.0000 - rmse: 49540.0273 - val_loss: 2755654912.0000 - val_rmse: 49303.1211\n",
      "Epoch 90/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2694199296.0000 - rmse: 49527.2930 - val_loss: 2731789056.0000 - val_rmse: 49250.2578\n",
      "Epoch 91/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2679514112.0000 - rmse: 49350.9766 - val_loss: 2707306240.0000 - val_rmse: 48827.3164\n",
      "Epoch 92/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2687297024.0000 - rmse: 49325.6758 - val_loss: 2711817984.0000 - val_rmse: 48894.3047\n",
      "Epoch 93/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2671240960.0000 - rmse: 49145.1562 - val_loss: 2709613824.0000 - val_rmse: 48919.2383\n",
      "Epoch 94/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2667118848.0000 - rmse: 49218.7227 - val_loss: 2728535552.0000 - val_rmse: 48930.3945\n",
      "Epoch 95/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2669000960.0000 - rmse: 49202.2422 - val_loss: 2723045632.0000 - val_rmse: 48802.6172\n",
      "Epoch 96/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2641628160.0000 - rmse: 48920.6836 - val_loss: 2755787776.0000 - val_rmse: 49189.1211\n",
      "Epoch 97/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2629135104.0000 - rmse: 48764.9961 - val_loss: 2790774272.0000 - val_rmse: 49526.9453\n",
      "Epoch 98/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2665990656.0000 - rmse: 49012.2773 - val_loss: 2680939776.0000 - val_rmse: 48824.9766\n",
      "Epoch 99/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2639964928.0000 - rmse: 49012.9180 - val_loss: 2834520064.0000 - val_rmse: 50194.7227\n",
      "Epoch 100/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2637602560.0000 - rmse: 48994.3945 - val_loss: 2901671936.0000 - val_rmse: 51009.8164\n",
      "Epoch 101/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2636330240.0000 - rmse: 48837.7461 - val_loss: 2667513088.0000 - val_rmse: 48464.5117\n",
      "Epoch 102/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2637447680.0000 - rmse: 48824.5977 - val_loss: 2691395072.0000 - val_rmse: 48532.8164\n",
      "Epoch 103/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2620657408.0000 - rmse: 48728.8750 - val_loss: 2732078080.0000 - val_rmse: 49330.9180\n",
      "Epoch 104/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2610799616.0000 - rmse: 48789.4570 - val_loss: 2674124544.0000 - val_rmse: 48400.3672\n",
      "Epoch 105/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2613283328.0000 - rmse: 48775.4727 - val_loss: 2700891648.0000 - val_rmse: 48812.8789\n",
      "Epoch 106/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2623971840.0000 - rmse: 49020.5469 - val_loss: 2641802240.0000 - val_rmse: 48292.6055\n",
      "Epoch 107/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2618820608.0000 - rmse: 48689.1797 - val_loss: 2693221632.0000 - val_rmse: 48576.1953\n",
      "Epoch 108/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2569260544.0000 - rmse: 48473.0859 - val_loss: 2751137792.0000 - val_rmse: 49351.4102\n",
      "Epoch 109/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2594655488.0000 - rmse: 48505.2852 - val_loss: 2783118848.0000 - val_rmse: 49359.1172\n",
      "Epoch 110/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2554514432.0000 - rmse: 48141.0430 - val_loss: 2687545088.0000 - val_rmse: 48534.0000\n",
      "Epoch 111/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2546319104.0000 - rmse: 48179.6133 - val_loss: 2754592000.0000 - val_rmse: 49073.2148\n",
      "Epoch 112/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2555827712.0000 - rmse: 48027.3125 - val_loss: 2690003456.0000 - val_rmse: 48615.3516\n",
      "Epoch 113/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2550372608.0000 - rmse: 48189.8242 - val_loss: 2691322112.0000 - val_rmse: 48650.7930\n",
      "Epoch 114/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2544799488.0000 - rmse: 48052.0195 - val_loss: 2918616064.0000 - val_rmse: 50573.6055\n",
      "Epoch 115/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2580221184.0000 - rmse: 48315.2031 - val_loss: 2758878720.0000 - val_rmse: 49568.5508\n",
      "Epoch 116/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2548591360.0000 - rmse: 48100.2266 - val_loss: 2618492928.0000 - val_rmse: 47892.8516\n",
      "Epoch 117/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2528082944.0000 - rmse: 47860.1602 - val_loss: 2692406784.0000 - val_rmse: 48613.4961\n",
      "Epoch 118/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2524604672.0000 - rmse: 47957.2773 - val_loss: 2666240000.0000 - val_rmse: 48400.1875\n",
      "Epoch 119/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2520638208.0000 - rmse: 47757.4570 - val_loss: 2616546304.0000 - val_rmse: 47853.9375\n",
      "Epoch 120/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2542118912.0000 - rmse: 47953.7734 - val_loss: 2642181120.0000 - val_rmse: 48423.2148\n",
      "Epoch 121/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2509126912.0000 - rmse: 47598.7031 - val_loss: 2673750272.0000 - val_rmse: 48448.5312\n",
      "Epoch 122/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2519450624.0000 - rmse: 47896.1094 - val_loss: 2667075072.0000 - val_rmse: 48233.7852\n",
      "Epoch 123/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2523559680.0000 - rmse: 47741.5781 - val_loss: 2639111424.0000 - val_rmse: 48213.0625\n",
      "Epoch 124/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2496361984.0000 - rmse: 47769.6602 - val_loss: 2679161344.0000 - val_rmse: 48827.3398\n",
      "Epoch 125/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2512435200.0000 - rmse: 47476.7734 - val_loss: 2752234240.0000 - val_rmse: 49133.0664\n",
      "Epoch 126/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2496255488.0000 - rmse: 47777.2695 - val_loss: 2726018816.0000 - val_rmse: 48795.2773\n",
      "Epoch 127/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2505696000.0000 - rmse: 47524.1797 - val_loss: 2758505216.0000 - val_rmse: 49171.0898\n",
      "Epoch 128/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2492966656.0000 - rmse: 47459.2266 - val_loss: 2625455360.0000 - val_rmse: 48195.0039\n",
      "Epoch 129/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2477034240.0000 - rmse: 47324.0938 - val_loss: 2605982976.0000 - val_rmse: 47952.9688\n",
      "Epoch 130/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2492406016.0000 - rmse: 47559.1680 - val_loss: 2673978112.0000 - val_rmse: 48428.6836\n",
      "Epoch 131/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2486275328.0000 - rmse: 47487.4883 - val_loss: 2677357056.0000 - val_rmse: 48466.5547\n",
      "Epoch 132/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2473845504.0000 - rmse: 47300.6836 - val_loss: 2643118592.0000 - val_rmse: 48128.0781\n",
      "Epoch 133/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2475993600.0000 - rmse: 47544.9727 - val_loss: 2615392768.0000 - val_rmse: 47848.2148\n",
      "Epoch 134/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2482473728.0000 - rmse: 47427.5547 - val_loss: 2743414016.0000 - val_rmse: 49232.6523\n",
      "Epoch 135/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2447224576.0000 - rmse: 47218.3867 - val_loss: 2673990144.0000 - val_rmse: 48553.4102\n",
      "Epoch 136/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2425899776.0000 - rmse: 47013.4258 - val_loss: 2873411072.0000 - val_rmse: 50436.4883\n",
      "Epoch 137/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2444742144.0000 - rmse: 47147.2539 - val_loss: 2610061312.0000 - val_rmse: 47805.6523\n",
      "Epoch 138/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2450629376.0000 - rmse: 47067.9727 - val_loss: 2717662208.0000 - val_rmse: 48902.7344\n",
      "Epoch 139/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2467255040.0000 - rmse: 47283.5078 - val_loss: 2604128768.0000 - val_rmse: 47910.3906\n",
      "Epoch 140/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2425439488.0000 - rmse: 46875.6953 - val_loss: 2820338432.0000 - val_rmse: 50022.2617\n",
      "Epoch 141/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2457584640.0000 - rmse: 47252.0273 - val_loss: 2590809088.0000 - val_rmse: 47641.4062\n",
      "Epoch 142/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2423378432.0000 - rmse: 46755.1953 - val_loss: 2655640832.0000 - val_rmse: 48246.9062\n",
      "Epoch 143/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2406130176.0000 - rmse: 46689.1172 - val_loss: 2579580416.0000 - val_rmse: 47700.6914\n",
      "Epoch 144/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2504110336.0000 - rmse: 47449.5078 - val_loss: 2626038272.0000 - val_rmse: 48344.1797\n",
      "Epoch 145/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2425623296.0000 - rmse: 46888.0156 - val_loss: 2582818304.0000 - val_rmse: 47711.0664\n",
      "Epoch 146/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2391383040.0000 - rmse: 46577.4375 - val_loss: 2638714880.0000 - val_rmse: 48005.9922\n",
      "Epoch 147/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2418857216.0000 - rmse: 46648.8281 - val_loss: 2648763392.0000 - val_rmse: 48485.9062\n",
      "Epoch 148/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2449616384.0000 - rmse: 47092.9492 - val_loss: 2572168192.0000 - val_rmse: 47382.1016\n",
      "Epoch 149/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2452288512.0000 - rmse: 47164.4961 - val_loss: 2600219648.0000 - val_rmse: 47719.5078\n",
      "Epoch 150/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2416939520.0000 - rmse: 46815.6758 - val_loss: 2582904832.0000 - val_rmse: 47583.4375\n",
      "Epoch 151/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2405128960.0000 - rmse: 46766.2891 - val_loss: 2609826048.0000 - val_rmse: 47870.7109\n",
      "Epoch 152/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2393397504.0000 - rmse: 46576.3828 - val_loss: 2568314112.0000 - val_rmse: 47475.7305\n",
      "Epoch 153/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2406698752.0000 - rmse: 46807.8281 - val_loss: 2692410880.0000 - val_rmse: 48746.7305\n",
      "Epoch 154/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2401977088.0000 - rmse: 46584.4805 - val_loss: 2671688448.0000 - val_rmse: 48318.9883\n",
      "Epoch 155/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2401693952.0000 - rmse: 46551.6055 - val_loss: 2599629056.0000 - val_rmse: 47945.5820\n",
      "Epoch 156/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2378775040.0000 - rmse: 46349.8281 - val_loss: 2580279552.0000 - val_rmse: 47754.2070\n",
      "Epoch 157/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2355706368.0000 - rmse: 46286.0156 - val_loss: 2582129664.0000 - val_rmse: 47629.8984\n",
      "Epoch 158/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2391544832.0000 - rmse: 46536.7070 - val_loss: 2622753536.0000 - val_rmse: 47974.5195\n",
      "Epoch 159/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2365750784.0000 - rmse: 46280.9062 - val_loss: 2726432768.0000 - val_rmse: 48845.2188\n",
      "Epoch 160/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2427215104.0000 - rmse: 46766.0117 - val_loss: 2560732416.0000 - val_rmse: 47441.4727\n",
      "Epoch 161/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2353472768.0000 - rmse: 46185.5312 - val_loss: 2582669312.0000 - val_rmse: 47664.1367\n",
      "Epoch 162/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2352494336.0000 - rmse: 46182.6602 - val_loss: 2700758272.0000 - val_rmse: 48497.3008\n",
      "Epoch 163/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2354772224.0000 - rmse: 46200.0977 - val_loss: 2586344960.0000 - val_rmse: 47559.3281\n",
      "Epoch 164/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2319537408.0000 - rmse: 45803.6797 - val_loss: 2609531392.0000 - val_rmse: 47948.6562\n",
      "Epoch 165/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2357072128.0000 - rmse: 46074.4492 - val_loss: 2563627008.0000 - val_rmse: 47480.1992\n",
      "Epoch 166/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2347089920.0000 - rmse: 46059.7930 - val_loss: 2571047936.0000 - val_rmse: 47643.2695\n",
      "Epoch 167/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2350677504.0000 - rmse: 46123.5898 - val_loss: 2697060608.0000 - val_rmse: 49097.2109\n",
      "Epoch 168/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2335435008.0000 - rmse: 46125.0586 - val_loss: 2578567168.0000 - val_rmse: 47684.9336\n",
      "Epoch 169/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2337007104.0000 - rmse: 46077.1055 - val_loss: 2601456640.0000 - val_rmse: 47650.1445\n",
      "Epoch 170/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2372446720.0000 - rmse: 46296.9570 - val_loss: 2605792768.0000 - val_rmse: 47635.4023\n",
      "Epoch 171/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2359333632.0000 - rmse: 46277.0273 - val_loss: 2566608128.0000 - val_rmse: 47533.2852\n",
      "Epoch 172/1000\n",
      "774/774 [==============================] - 6s 8ms/step - loss: 2335302912.0000 - rmse: 46038.1719 - val_loss: 2728992512.0000 - val_rmse: 49035.4375\n",
      "Epoch 173/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2314766848.0000 - rmse: 45899.7461 - val_loss: 2575108096.0000 - val_rmse: 47551.2422\n",
      "Epoch 174/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2341961472.0000 - rmse: 46270.4609 - val_loss: 2544778496.0000 - val_rmse: 47148.8516\n",
      "Epoch 175/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2341699584.0000 - rmse: 46025.9219 - val_loss: 2618986752.0000 - val_rmse: 47881.8477\n",
      "Epoch 176/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2316841472.0000 - rmse: 45751.6797 - val_loss: 2607957760.0000 - val_rmse: 48024.7734\n",
      "Epoch 177/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2337556224.0000 - rmse: 46061.2617 - val_loss: 2551892992.0000 - val_rmse: 47234.9688\n",
      "Epoch 178/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2296878336.0000 - rmse: 45575.0430 - val_loss: 2580244480.0000 - val_rmse: 47706.6094\n",
      "Epoch 179/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2375104000.0000 - rmse: 46357.4844 - val_loss: 2629079552.0000 - val_rmse: 47995.7031\n",
      "Epoch 180/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2270548736.0000 - rmse: 45422.4180 - val_loss: 2582034944.0000 - val_rmse: 47443.9453\n",
      "Epoch 181/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2295307776.0000 - rmse: 45676.5625 - val_loss: 2631023104.0000 - val_rmse: 48137.0742\n",
      "Epoch 182/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2289681408.0000 - rmse: 45517.2969 - val_loss: 2651211264.0000 - val_rmse: 48646.0039\n",
      "Epoch 183/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2276093440.0000 - rmse: 45471.9336 - val_loss: 2606714112.0000 - val_rmse: 47752.7969\n",
      "Epoch 184/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2313090816.0000 - rmse: 45846.0781 - val_loss: 2624334336.0000 - val_rmse: 48333.3555\n",
      "Epoch 185/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2288166144.0000 - rmse: 45520.4531 - val_loss: 2635353600.0000 - val_rmse: 48285.5078\n",
      "Epoch 186/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2302775808.0000 - rmse: 45719.9375 - val_loss: 2589222400.0000 - val_rmse: 47866.7148\n",
      "Epoch 187/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2273966080.0000 - rmse: 45479.7500 - val_loss: 2567164416.0000 - val_rmse: 47452.2930\n",
      "Epoch 188/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2279041280.0000 - rmse: 45540.0977 - val_loss: 2666913024.0000 - val_rmse: 48687.7422\n",
      "Epoch 189/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2304205312.0000 - rmse: 45585.4922 - val_loss: 2583053568.0000 - val_rmse: 47628.3047\n",
      "Epoch 190/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2298430464.0000 - rmse: 45577.1836 - val_loss: 2559776256.0000 - val_rmse: 47360.2969\n",
      "Epoch 191/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2283211520.0000 - rmse: 45517.9258 - val_loss: 2550662912.0000 - val_rmse: 47563.0977\n",
      "Epoch 192/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2315362816.0000 - rmse: 45643.0820 - val_loss: 2570937600.0000 - val_rmse: 47583.0156\n",
      "Epoch 193/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2299850496.0000 - rmse: 45621.2148 - val_loss: 2610763264.0000 - val_rmse: 48066.4688\n",
      "Epoch 194/1000\n",
      "774/774 [==============================] - 7s 9ms/step - loss: 2245564416.0000 - rmse: 45169.3398 - val_loss: 2569109760.0000 - val_rmse: 47476.7344\n",
      "CPU times: user 25min 3s, sys: 1min 19s, total: 26min 22s\n",
      "Wall time: 21min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;keras&#x27;,\n",
       "                 KerasRegressor(batch_size=16, callbacks=[&lt;keras.src.callbacks.EarlyStopping object at 0x7f20d5c1b950&gt;], epochs=1000, model=&lt;keras.src.engine.sequential.Sequential object at 0x7f20d5c35250&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;keras&#x27;,\n",
       "                 KerasRegressor(batch_size=16, callbacks=[&lt;keras.src.callbacks.EarlyStopping object at 0x7f20d5c1b950&gt;], epochs=1000, model=&lt;keras.src.engine.sequential.Sequential object at 0x7f20d5c35250&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;keras.src.engine.sequential.Sequential object at 0x7f20d5c35250&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=16\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.src.callbacks.EarlyStopping object at 0x7f20d5c1b950&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1000\n",
       ")</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('keras',\n",
       "                 KerasRegressor(batch_size=16, callbacks=[<keras.src.callbacks.EarlyStopping object at 0x7f20d5c1b950>], epochs=1000, model=<keras.src.engine.sequential.Sequential object at 0x7f20d5c35250>))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([])\n",
    "pipe.steps.append((\"scaler\", StandardScaler()))\n",
    "\n",
    "pipe.fit(X_train)\n",
    "X_test_transformed = pipe.transform(X_test)\n",
    "\n",
    "keras_reg = build_keras_regressor(build_model(len(X_train.columns), [64, 64, 64, 64, 64, 64], 1, 0.1), batch_size=16, patience=20, epochs=1000, verbose=1)\n",
    "pipe.steps.append((\"keras\", keras_reg))\n",
    "\n",
    "pipe.fit(X_train, y_train, keras__validation_data=(X_test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = pipe.named_steps['keras'].history_\n",
    "plot_rmse(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50445.79560673367"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "metrics.root_mean_squared_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
